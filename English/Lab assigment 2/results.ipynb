{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import itertools\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='rm -f images/*', returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elimina todo lo que hay en la carpeta /images que tenga la extensiÃ³n .png (usando rm)\n",
    "\n",
    "subprocess.run(\"rm -f images/*\", shell=True)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando con eta=0.01, mu=0.5, l=2, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=2, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=2, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=2, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=2, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=2, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=2, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=2, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=4, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=4, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=4, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=4, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=4, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=4, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=4, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=4, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=6, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=6, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=6, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=6, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=6, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=6, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=6, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=6, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=8, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=8, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=8, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=8, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=8, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=8, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=8, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=8, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=10, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=10, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=10, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=10, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=10, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=10, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=10, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=10, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=12, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=12, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=12, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=12, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=12, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=12, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=12, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=12, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=14, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=14, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=14, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=14, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=14, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=14, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=14, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=14, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=16, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=16, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=16, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=16, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=16, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=16, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=16, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=16, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=18, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=18, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=18, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=18, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=18, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=18, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=18, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.5, l=18, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=2, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=2, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=2, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=2, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=2, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=2, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=2, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=2, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=4, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=4, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=4, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=4, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=4, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=4, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=4, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=4, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=6, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=6, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=6, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=6, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=6, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=6, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=6, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=6, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=8, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=8, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=8, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=8, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=8, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=8, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=8, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=8, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=10, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=10, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=10, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=10, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=10, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=10, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=10, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=10, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=12, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=12, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=12, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=12, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=12, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=12, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=12, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=12, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=14, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=14, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=14, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=14, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=14, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=14, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=14, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=14, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=16, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=16, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=16, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=16, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=16, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=16, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=16, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=16, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=18, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=18, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=18, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=18, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=18, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=18, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=18, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.7, l=18, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=2, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=2, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=2, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=2, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=2, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=2, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=2, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=2, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=4, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=4, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=4, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=4, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=4, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=4, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=4, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=4, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=6, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=6, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=6, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=6, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=6, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=6, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=6, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=6, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=8, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=8, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=8, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=8, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=8, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=8, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=8, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=8, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=10, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=10, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=10, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=10, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=10, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=10, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=10, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=10, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=12, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=12, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=12, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=12, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=12, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=12, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=12, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=12, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=14, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=14, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=14, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=14, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=14, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=14, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=14, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=14, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=16, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=16, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=16, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=16, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=16, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=16, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=16, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=16, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=18, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=18, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=18, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=18, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=18, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=18, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=18, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.01, mu=0.9, l=18, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=2, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=2, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=2, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=2, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=2, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=2, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=2, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=2, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=4, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=4, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=4, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=4, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=4, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=4, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=4, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=4, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=6, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=6, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=6, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=6, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=6, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=6, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=6, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=6, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=8, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=8, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=8, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=8, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=8, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=8, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=8, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=8, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=10, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=10, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=10, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=10, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=10, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=10, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=10, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=10, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=12, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=12, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=12, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=12, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=12, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=12, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=12, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=12, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=14, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=14, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=14, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=14, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=14, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=14, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=14, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=14, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=16, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=16, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=16, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=16, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=16, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=16, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=16, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=16, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=18, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=18, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=18, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=18, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=18, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=18, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=18, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.5, l=18, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=2, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=2, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=2, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=2, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=2, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=2, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=2, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=2, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=4, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=4, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=4, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=4, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=4, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=4, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=4, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=4, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=6, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=6, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=6, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=6, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=6, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=6, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=6, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=6, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=8, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=8, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=8, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=8, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=8, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=8, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=8, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=8, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=10, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=10, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=10, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=10, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=10, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=10, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=10, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=10, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=12, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=12, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=12, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=12, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=12, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=12, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=12, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=12, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=14, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=14, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=14, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=14, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=14, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=14, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=14, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=14, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=16, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=16, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=16, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=16, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=16, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=16, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=16, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=16, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=18, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=18, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=18, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=18, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=18, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=18, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=18, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.7, l=18, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=2, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=2, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=2, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=2, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=2, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=2, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=2, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=2, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=4, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=4, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=4, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=4, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=4, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=4, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=4, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=4, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=6, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=6, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=6, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=6, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=6, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=6, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=6, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=6, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=8, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=8, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=8, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=8, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=8, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=8, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=8, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=8, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=10, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=10, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=10, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=10, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=10, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=10, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=10, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=10, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=12, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=12, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=12, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=12, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=12, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=12, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=12, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=12, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=14, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=14, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=14, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=14, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=14, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=14, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=14, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=14, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=16, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=16, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=16, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=16, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=16, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=16, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=16, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=16, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=18, h=5, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=18, h=7, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=18, h=9, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=18, h=11, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=18, h=13, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=18, h=15, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=18, h=17, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Ejecutando con eta=0.1, mu=0.9, l=18, h=19, i=2000, train=./dat/train_mpg.dat, test=./dat/test_mpg.dat\n",
      "Resultados guardados en /home/yabiel/Downloads/skeletonLA1IMC/results.json\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import itertools\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Definir los diferentes parÃ¡metros\n",
    "etas = [0.01, 0.1]\n",
    "mus = [0.5,0.7, 0.9]\n",
    "layers = [2, 4,6,8,10,12,14,16,18]\n",
    "neurons = [5,7,9,11,13,15,17,19]\n",
    "iterations = [2000]\n",
    "train_files = [\"./dat/train_mpg.dat\"]\n",
    "test_files = [\"./dat/test_mpg.dat\"]\n",
    "\n",
    "# Resultado JSON\n",
    "results = {}\n",
    "\n",
    "# ExpresiÃ³n regular para extraer los errores de entrenamiento y prueba\n",
    "train_test_regex = r\"Train error \\(Mean \\+- SD\\): ([\\d\\.eE+-]+) \\+- ([\\d\\.eE+-]+)\\nTest error \\(Mean \\+- SD\\):\\s+([\\d\\.eE+-]+) \\+- ([\\d\\.eE+-]+)\"\n",
    "\n",
    "# Iterar sobre los Ã­ndices para asociar correctamente train y test\n",
    "for idx in range(len(train_files)):\n",
    "    train_file = train_files[idx]\n",
    "    test_file = test_files[idx]\n",
    "\n",
    "    # Iterar sobre todas las combinaciones de eta, mu, layers, neurons e iteraciones\n",
    "    for eta, mu, l, h, i in itertools.product(etas, mus, layers, neurons, iterations):\n",
    "        print(f\"Ejecutando con eta={eta}, mu={mu}, l={l}, h={h}, i={i}, train={train_file}, test={test_file}\")\n",
    "\n",
    "        # Ejecutar el programa la1.cpp (asegÃºrate de que el programa se ejecute solo una vez por combinaciÃ³n)\n",
    "        result = subprocess.run(\n",
    "            [\"./bin/la1\", \"-t\", train_file,\"-s\", \"-T\", test_file, \"-e\", str(eta), \"-m\", str(mu), \"-l\", str(l), \"-h\", str(h), \"-i\", str(i)],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "\n",
    "        # Extraer el error final usando la regex\n",
    "        final_report = re.search(train_test_regex, result.stdout, re.DOTALL)\n",
    "        if final_report:\n",
    "            train_mean, train_std, test_mean, test_std = final_report.groups()\n",
    "\n",
    "            # Guardar resultados en el JSON con la estructura solicitada\n",
    "            dataset_name = train_file.split('/')[-1].split('.')[0]\n",
    "            if dataset_name not in results:\n",
    "                results[dataset_name] = {}\n",
    "\n",
    "            eta_mu_key = f\"eta={eta} mu={mu}\"\n",
    "            if eta_mu_key not in results[dataset_name]:\n",
    "                results[dataset_name][eta_mu_key] = {}\n",
    "\n",
    "            # Iteraciones como primera clave\n",
    "            if i not in results[dataset_name][eta_mu_key]:\n",
    "                results[dataset_name][eta_mu_key][i] = {}\n",
    "\n",
    "            # Capas y luego neuronas\n",
    "            if l not in results[dataset_name][eta_mu_key][i]:\n",
    "                results[dataset_name][eta_mu_key][i][l] = {}\n",
    "\n",
    "            if h not in results[dataset_name][eta_mu_key][i][l]:\n",
    "                # Solo almacenamos los resultados una vez por combinaciÃ³n de parÃ¡metros\n",
    "                results[dataset_name][eta_mu_key][i][l][h] = {\n",
    "                    \"train_result\": {\n",
    "                        \"mean\": float(train_mean),\n",
    "                        \"std\": float(train_std)\n",
    "                    },\n",
    "                    \"test_result\": {\n",
    "                        \"mean\": float(test_mean),\n",
    "                        \"std\": float(test_std)\n",
    "                    }\n",
    "                }\n",
    "\n",
    "# Guardar resultados en un archivo JSON usando una ruta absoluta\n",
    "try:\n",
    "    with open(os.path.abspath('results.json'), 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    print(f\"Resultados guardados en {os.path.abspath('results.json')}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar el archivo JSON: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './images/'\n",
    "\n",
    "# FunciÃ³n para calcular diferencias y mostrar el grÃ¡fico de crecimiento del error\n",
    "def calculate_differences(error_matrix, eta, mu, iteration, neurons, layers, result_type, name):\n",
    "    horizontal_diff = np.abs(np.diff(error_matrix, axis=1))\n",
    "    vertical_diff = np.abs(np.diff(error_matrix, axis=0))\n",
    "\n",
    "    horizontal_labels = [f\"{neurons[i]}-{neurons[i+1]}\" for i in range(len(neurons)-1)]\n",
    "    vertical_labels = [f\"{layers[i]}-{layers[i+1]}\" for i in range(len(layers)-1)]\n",
    "\n",
    "    # Crear mapas de calor para las diferencias horizontales y verticales\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Mapa de calor horizontal\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(horizontal_diff, annot=True, fmt=\".4f\", cmap='coolwarm', xticklabels=horizontal_labels, yticklabels=layers)\n",
    "    plt.title(f'Horizontal Error Change (eta={eta}, mu={mu}, iter={iteration})')\n",
    "    plt.xlabel('Neuron Transitions')\n",
    "    plt.ylabel('Layers')\n",
    "\n",
    "    # Mapa de calor vertical\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(vertical_diff, annot=True, fmt=\".4f\", cmap='coolwarm', xticklabels=neurons, yticklabels=vertical_labels)\n",
    "    plt.title(f'Vertical Error Change (eta={eta}, mu={mu}, iter={iteration})')\n",
    "    plt.xlabel('Neurons')\n",
    "    plt.ylabel('Layer Transitions')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f'h_e{eta}_m{mu}_{iteration}_{result_type}_{name}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Proceso para generar tablas, grÃ¡ficos y Pareto para cada combinaciÃ³n de eta y mu\n",
    "def process_results(results, neurons, layers):\n",
    "    for dataset_name, result_data in results.items():\n",
    "        for eta_mu_key, config_data in result_data.items():\n",
    "            eta_mu_vals = eta_mu_key.split(' ')\n",
    "            eta = float(eta_mu_vals[0].split('=')[1])\n",
    "            mu = float(eta_mu_vals[1].split('=')[1])\n",
    "\n",
    "            for iteration, layer_data in config_data.items():\n",
    "                # Crear las matrices para train y test\n",
    "                train_error_matrix = np.zeros((len(layers), len(neurons)))\n",
    "                test_error_matrix = np.zeros((len(layers), len(neurons)))\n",
    "\n",
    "                # Recoger los errores en forma de matriz para cada combinaciÃ³n de l y h\n",
    "                for l_val, neuron_data in layer_data.items():\n",
    "                    for h_val, errors in neuron_data.items():\n",
    "                        # Extraer errores de train y test\n",
    "                        train_error = errors[\"train_result\"][\"mean\"]\n",
    "                        test_error = errors[\"test_result\"][\"mean\"]\n",
    "\n",
    "                        layer_idx = layers.index(int(l_val))  # Convertir l_val a entero\n",
    "                        neuron_idx = neurons.index(int(h_val))  # Convertir h_val a entero\n",
    "\n",
    "                        # Almacenar los errores en las matrices correspondientes\n",
    "                        train_error_matrix[layer_idx, neuron_idx] = train_error\n",
    "                        test_error_matrix[layer_idx, neuron_idx] = test_error\n",
    "\n",
    "                # Calcular las diferencias de error y generar grÃ¡ficos de crecimiento para train_result\n",
    "                calculate_differences(train_error_matrix, eta, mu, iteration, neurons, layers, result_type=\"Train\", name=dataset_name)\n",
    "\n",
    "                # Generar la grÃ¡fica del frente de Pareto en 3D para train_result\n",
    "                plot_pareto_3d(train_error_matrix, eta, mu, iteration, neurons, layers, result_type=\"Train\", name=dataset_name)\n",
    "\n",
    "                # Calcular las diferencias de error y generar grÃ¡ficos de crecimiento para test_result\n",
    "                calculate_differences(test_error_matrix, eta, mu, iteration, neurons, layers, result_type=\"Test\", name=dataset_name)\n",
    "\n",
    "                # Generar la grÃ¡fica del frente de Pareto en 3D para test_result\n",
    "                plot_pareto_3d(test_error_matrix, eta, mu, iteration, neurons, layers, result_type=\"Test\", name=dataset_name)\n",
    "\n",
    "                \n",
    "def find_best_results(results):\n",
    "    best_train_result = float('inf')\n",
    "    best_test_result = float('inf')\n",
    "    best_config_train = None\n",
    "    best_config_test = None\n",
    "\n",
    "    # Recorrer cada combinaciÃ³n de dataset, eta, mu, iteraciones, capas, neuronas\n",
    "    for dataset_name, result_data in results.items():\n",
    "        for eta_mu_key, config_data in result_data.items():\n",
    "            eta_mu_vals = eta_mu_key.split(' ')\n",
    "            eta = float(eta_mu_vals[0].split('=')[1])\n",
    "            mu = float(eta_mu_vals[1].split('=')[1])\n",
    "\n",
    "            for iteration, layer_data in config_data.items():\n",
    "                for l_val, neuron_data in layer_data.items():\n",
    "                    for h_val, errors in neuron_data.items():\n",
    "                        # Comparar el train_result (media del error)\n",
    "                        train_error = errors[\"train_result\"][\"mean\"]\n",
    "                        if train_error < best_train_result:\n",
    "                            best_train_result = train_error\n",
    "                            best_config_train = {\n",
    "                                \"dataset\": dataset_name,\n",
    "                                \"eta\": eta,\n",
    "                                \"mu\": mu,\n",
    "                                \"iterations\": iteration,\n",
    "                                \"layers\": l_val,\n",
    "                                \"neurons\": h_val,\n",
    "                                \"train_error\": train_error\n",
    "                            }\n",
    "                        \n",
    "                        # Comparar el test_result (media del error)\n",
    "                        test_error = errors[\"test_result\"][\"mean\"]\n",
    "                        if test_error < best_test_result:\n",
    "                            best_test_result = test_error\n",
    "                            best_config_test = {\n",
    "                                \"dataset\": dataset_name,\n",
    "                                \"eta\": eta,\n",
    "                                \"mu\": mu,\n",
    "                                \"iterations\": iteration,\n",
    "                                \"layers\": l_val,\n",
    "                                \"neurons\": h_val,\n",
    "                                \"test_error\": test_error\n",
    "                            }\n",
    "\n",
    "    # Retornar los mejores resultados\n",
    "    return best_config_train, best_config_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FunciÃ³n para identificar las soluciones que estÃ¡n en el frente de Pareto\n",
    "def is_dominated(point, candidates):\n",
    "    for candidate in candidates:\n",
    "        if all(candidate <= point) and any(candidate < point):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def pareto_frontier(points):\n",
    "    pareto_points = []\n",
    "    for point in points:\n",
    "        if not is_dominated(point, points):\n",
    "            pareto_points.append(point)\n",
    "    return np.array(pareto_points)\n",
    "\n",
    "# FunciÃ³n para dibujar el frente de Pareto en 3D\n",
    "def plot_pareto_3d(error_matrix, eta, mu, iteration, neurons, layers, result_type, name):\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Crear la lista de puntos (combinaciones de capas y neuronas)\n",
    "    layers_pareto, neurons_pareto = np.meshgrid(layers, neurons, indexing=\"ij\")\n",
    "    points = np.c_[neurons_pareto.flatten(), layers_pareto.flatten(), error_matrix.flatten()]\n",
    "\n",
    "    # Identificar los puntos en el frente de Pareto\n",
    "    pareto_points = pareto_frontier(points)\n",
    "\n",
    "    # Separar los puntos en dos categorÃ­as: en el frente de Pareto y no en el frente de Pareto\n",
    "    non_pareto_points = np.array([p for p in points if not any(np.all(p == pp) for pp in pareto_points)])\n",
    "\n",
    "    # Graficar los puntos que no estÃ¡n en el frente de Pareto\n",
    "    if len(non_pareto_points) > 0:\n",
    "        ax.scatter(non_pareto_points[:, 0], non_pareto_points[:, 1], non_pareto_points[:, 2], \n",
    "                   c='blue', marker='o', s=100, label='Non-Pareto Points')\n",
    "\n",
    "    # Graficar los puntos que estÃ¡n en el frente de Pareto\n",
    "    if len(pareto_points) > 0:\n",
    "        ax.scatter(pareto_points[:, 0], pareto_points[:, 1], pareto_points[:, 2], \n",
    "                   c='red', marker='o', s=100, label='Pareto Frontier', edgecolor='black')\n",
    "\n",
    "    # Configurar etiquetas y tÃ­tulos\n",
    "    ax.set_xlabel('Number of Neurons')\n",
    "    ax.set_ylabel('Number of Layers')\n",
    "    ax.set_zlabel('Error')\n",
    "\n",
    "    ax.set_title(f'Pareto Front in 3D (eta={eta}, mu={mu}, iter={iteration}, {result_type})')\n",
    "    ax.legend()\n",
    "\n",
    "    # Guardar el grÃ¡fico\n",
    "    plt.savefig(os.path.join(output_dir, f'p_e{eta}_m{mu}_{iteration}_{result_type}_{name}.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table_for_eta_mu_iteration(results, eta, mu, iteration, name):\n",
    "    eta_mu_key = f\"eta={eta} mu={mu}\"\n",
    "\n",
    "    # Verificar que exista la combinaciÃ³n eta-mu en los resultados\n",
    "    if eta_mu_key not in results[name]:\n",
    "        print(f\"Error: No se encontrÃ³ la combinaciÃ³n eta={eta}, mu={mu}.\")\n",
    "        return\n",
    "    \n",
    "    # Verificar que existan resultados para las iteraciones dadas (asegurarse de que se trate como cadena)\n",
    "    if str(iteration) not in results[name][eta_mu_key]:\n",
    "        print(f\"Error: No se encontraron resultados para {iteration} iteraciones.\")\n",
    "        return\n",
    "\n",
    "    # Obtener los resultados para las iteraciones dadas (como cadena)\n",
    "    iteration_data = results[name][eta_mu_key][str(iteration)]\n",
    "    \n",
    "    # Inicializar las estructuras de las tablas para train y test\n",
    "    train_results = {}\n",
    "    test_results = {}\n",
    "\n",
    "    # Procesar cada capa y neuronas\n",
    "    for layer, neuron_data in iteration_data.items():\n",
    "        train_results[layer] = {}\n",
    "        test_results[layer] = {}\n",
    "        for neuron, errors in neuron_data.items():\n",
    "            train_results[layer][neuron] = errors[\"train_result\"][\"mean\"]\n",
    "            test_results[layer][neuron] = errors[\"test_result\"][\"mean\"]\n",
    "\n",
    "    # Generar la tabla en formato LaTeX para los resultados de entrenamiento y prueba\n",
    "    generate_latex_table(train_results, eta, mu, iteration, name, table_type=\"Train\")\n",
    "    generate_latex_table(test_results, eta, mu, iteration, name, table_type=\"Test\")\n",
    "\n",
    "\n",
    "# FunciÃ³n para generar la tabla en formato LaTeX\n",
    "def generate_latex_table(results_dict, eta, mu, iteration,name, table_type):\n",
    "    # Ordenar las capas y las neuronas\n",
    "    layer_keys = sorted(results_dict.keys(), key=int)\n",
    "    neuron_keys = sorted(next(iter(results_dict.values())).keys(), key=int)\n",
    "    \n",
    "    # Comenzar la tabla en LaTeX\n",
    "    latex_table = r\"\\begin{table}[H]\" + \"\\n\" + r\"    \\centering\" + \"\\n\"\n",
    "    latex_table += r\"    \\resizebox{\\textwidth}{!}{% \" + \"\\n\"\n",
    "    latex_table += r\"    \\begin{tabular}{c\" + \"c\" * len(neuron_keys) + \"}\\n\"\n",
    "    \n",
    "    # Encabezado de la tabla\n",
    "    latex_table += r\"        Layers/neurons & \" + \" & \".join(str(neuron) for neuron in neuron_keys) + r\" \\\\\" + \"\\n\"\n",
    "    \n",
    "    # Filas con los resultados de las capas\n",
    "    for layer in layer_keys:\n",
    "        row = f\"        {layer} & \" + \" & \".join(f\"{results_dict[layer][neuron]:.6f}\" for neuron in neuron_keys) + r\" \\\\\"\n",
    "        latex_table += row + \"\\n\"\n",
    "\n",
    "    # Finalizar la tabla\n",
    "    latex_table += r\"    \\end{tabular}\" + \"\\n\"\n",
    "    latex_table += r\"    }\" + \"\\n\"\n",
    "    latex_table += f\"    \\\\caption{{{table_type} results for eta={eta}, mu={mu}, iterations={iteration}}}\" + \"\\n\"\n",
    "    latex_table += f\"    \\\\label{{tab:{table_type.lower()}_results_{name}}}\" + \"\\n\"\n",
    "    latex_table += r\"\\end{table}\" + \"\\n\"\n",
    "    \n",
    "    # Imprimir la tabla por consola\n",
    "    print(f\"{table_type} Table (LaTeX):\")\n",
    "    print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': 'train_mpg', 'eta': 0.1, 'mu': 0.5, 'iterations': '2000', 'layers': '4', 'neurons': '11', 'test_error': 0.00374197}\n",
      "Train Table (LaTeX):\n",
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\resizebox{\\textwidth}{!}{% \n",
      "    \\begin{tabular}{ccccccccc}\n",
      "        Layers/neurons & 5 & 7 & 9 & 11 & 13 & 15 & 17 & 19 \\\\\n",
      "        2 & 0.003229 & 0.002892 & 0.002753 & 0.002535 & 0.002314 & 0.002147 & 0.002566 & 0.002565 \\\\\n",
      "        4 & 0.003495 & 0.002659 & 0.002451 & 0.002343 & 0.002401 & 0.002193 & 0.002160 & 0.002046 \\\\\n",
      "        6 & 0.044632 & 0.027892 & 0.002443 & 0.002456 & 0.002204 & 0.002059 & 0.002085 & 0.002068 \\\\\n",
      "        8 & 0.044633 & 0.044633 & 0.044634 & 0.044624 & 0.044631 & 0.044628 & 0.019147 & 0.010757 \\\\\n",
      "        10 & 0.044633 & 0.044634 & 0.044635 & 0.044633 & 0.044637 & 0.044634 & 0.044635 & 0.044634 \\\\\n",
      "        12 & 0.044634 & 0.044634 & 0.044635 & 0.044635 & 0.044636 & 0.044635 & 0.044633 & 0.044635 \\\\\n",
      "        14 & 0.044663 & 0.044635 & 0.044635 & 0.044634 & 0.044634 & 0.044636 & 0.044634 & 0.044636 \\\\\n",
      "        16 & 0.044634 & 0.044633 & 0.044633 & 0.044634 & 0.044636 & 0.044636 & 0.044637 & 0.044641 \\\\\n",
      "        18 & 0.044633 & 0.044634 & 0.044634 & 0.044636 & 0.044634 & 0.044639 & 0.044635 & 0.044637 \\\\\n",
      "    \\end{tabular}\n",
      "    }\n",
      "    \\caption{Train results for eta=0.1, mu=0.5, iterations=2000}\n",
      "    \\label{tab:train_results_train_mpg}\n",
      "\\end{table}\n",
      "\n",
      "Test Table (LaTeX):\n",
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\resizebox{\\textwidth}{!}{% \n",
      "    \\begin{tabular}{ccccccccc}\n",
      "        Layers/neurons & 5 & 7 & 9 & 11 & 13 & 15 & 17 & 19 \\\\\n",
      "        2 & 0.004333 & 0.005171 & 0.004589 & 0.004757 & 0.004108 & 0.004607 & 0.004892 & 0.004795 \\\\\n",
      "        4 & 0.004979 & 0.004690 & 0.004765 & 0.003742 & 0.004611 & 0.004208 & 0.005110 & 0.004822 \\\\\n",
      "        6 & 0.036523 & 0.023657 & 0.004911 & 0.004700 & 0.004768 & 0.004549 & 0.004558 & 0.005011 \\\\\n",
      "        8 & 0.036514 & 0.036528 & 0.036521 & 0.036562 & 0.036583 & 0.036542 & 0.017843 & 0.011465 \\\\\n",
      "        10 & 0.036514 & 0.036472 & 0.036540 & 0.036526 & 0.036511 & 0.036511 & 0.036527 & 0.036524 \\\\\n",
      "        12 & 0.036539 & 0.036518 & 0.036494 & 0.036540 & 0.036539 & 0.036516 & 0.036543 & 0.036519 \\\\\n",
      "        14 & 0.036649 & 0.036512 & 0.036517 & 0.036494 & 0.036510 & 0.036483 & 0.036506 & 0.036586 \\\\\n",
      "        16 & 0.036486 & 0.036506 & 0.036489 & 0.036520 & 0.036580 & 0.036498 & 0.036489 & 0.036488 \\\\\n",
      "        18 & 0.036485 & 0.036518 & 0.036522 & 0.036537 & 0.036538 & 0.036462 & 0.036473 & 0.036538 \\\\\n",
      "    \\end{tabular}\n",
      "    }\n",
      "    \\caption{Test results for eta=0.1, mu=0.5, iterations=2000}\n",
      "    \\label{tab:test_results_train_mpg}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar el archivo JSON\n",
    "with open('results.json', 'r') as f:\n",
    "    loaded_results = json.load(f)\n",
    "\n",
    "best_config_train, best_config_test = find_best_results(loaded_results)\n",
    "print(best_config_test)\n",
    "generate_latex_table_for_eta_mu_iteration(loaded_results, eta=best_config_test[\"eta\"], mu=best_config_test[\"mu\"], iteration=int(best_config_test[\"iterations\"]), name=best_config_test[\"dataset\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar resultados y analizar\n",
    "with open('results.json', 'r') as f:\n",
    "    loaded_results = json.load(f)\n",
    "etas = [0.01, 0.1]\n",
    "mus = [0.5,0.7, 0.9]\n",
    "layers = [2, 4,6,8,10,12,14,16,18]\n",
    "neurons = [5,7,9,11,13,15,17,19]\n",
    "iterations = [2000]\n",
    "train_files = [\"./dat/train_mpg.dat\"]\n",
    "test_files = [\"./dat/test_mpg.dat\"]\n",
    "iterations = [2000]\n",
    "process_results(loaded_results, neurons, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cadena = \"\"\"\n",
    "Iteration 1\t Training error: 0.0451547\n",
    "Iteration 2\t Training error: 0.0414617\n",
    "Iteration 3\t Training error: 0.0269586\n",
    "Iteration 4\t Training error: 0.0116981\n",
    "Iteration 5\t Training error: 0.0110865\n",
    "Iteration 6\t Training error: 0.0107494\n",
    "Iteration 7\t Training error: 0.010356\n",
    "Iteration 8\t Training error: 0.00981123\n",
    "Iteration 9\t Training error: 0.00921723\n",
    "Iteration 10\t Training error: 0.00867351\n",
    "Iteration 11\t Training error: 0.00820709\n",
    "Iteration 12\t Training error: 0.00781343\n",
    "Iteration 13\t Training error: 0.00748034\n",
    "Iteration 14\t Training error: 0.00719587\n",
    "Iteration 15\t Training error: 0.00695051\n",
    "Iteration 16\t Training error: 0.00673718\n",
    "Iteration 17\t Training error: 0.00655067\n",
    "Iteration 18\t Training error: 0.00638698\n",
    "Iteration 19\t Training error: 0.00624282\n",
    "Iteration 20\t Training error: 0.00611541\n",
    "Iteration 21\t Training error: 0.00600231\n",
    "Iteration 22\t Training error: 0.00590144\n",
    "Iteration 23\t Training error: 0.005811\n",
    "Iteration 24\t Training error: 0.00572949\n",
    "Iteration 25\t Training error: 0.00565562\n",
    "Iteration 26\t Training error: 0.00558834\n",
    "Iteration 27\t Training error: 0.00552674\n",
    "Iteration 28\t Training error: 0.00547009\n",
    "Iteration 29\t Training error: 0.00541774\n",
    "Iteration 30\t Training error: 0.00536917\n",
    "Iteration 31\t Training error: 0.00532393\n",
    "Iteration 32\t Training error: 0.00528161\n",
    "Iteration 33\t Training error: 0.0052419\n",
    "Iteration 34\t Training error: 0.0052045\n",
    "Iteration 35\t Training error: 0.00516918\n",
    "Iteration 36\t Training error: 0.00513571\n",
    "Iteration 37\t Training error: 0.00510392\n",
    "Iteration 38\t Training error: 0.00507364\n",
    "Iteration 39\t Training error: 0.00504475\n",
    "Iteration 40\t Training error: 0.00501711\n",
    "Iteration 41\t Training error: 0.00499065\n",
    "Iteration 42\t Training error: 0.00496526\n",
    "Iteration 43\t Training error: 0.00494087\n",
    "Iteration 44\t Training error: 0.00491742\n",
    "Iteration 45\t Training error: 0.00489486\n",
    "Iteration 46\t Training error: 0.00487313\n",
    "Iteration 47\t Training error: 0.0048522\n",
    "Iteration 48\t Training error: 0.00483202\n",
    "Iteration 49\t Training error: 0.00481256\n",
    "Iteration 50\t Training error: 0.0047938\n",
    "Iteration 51\t Training error: 0.0047757\n",
    "Iteration 52\t Training error: 0.00475823\n",
    "Iteration 53\t Training error: 0.00474138\n",
    "Iteration 54\t Training error: 0.00472512\n",
    "Iteration 55\t Training error: 0.00470942\n",
    "Iteration 56\t Training error: 0.00469427\n",
    "Iteration 57\t Training error: 0.00467964\n",
    "Iteration 58\t Training error: 0.00466553\n",
    "Iteration 59\t Training error: 0.0046519\n",
    "Iteration 60\t Training error: 0.00463876\n",
    "Iteration 61\t Training error: 0.00462608\n",
    "Iteration 62\t Training error: 0.00461385\n",
    "Iteration 63\t Training error: 0.00460207\n",
    "Iteration 64\t Training error: 0.00459072\n",
    "Iteration 65\t Training error: 0.00457981\n",
    "Iteration 66\t Training error: 0.00456932\n",
    "Iteration 67\t Training error: 0.00455926\n",
    "Iteration 68\t Training error: 0.00454962\n",
    "Iteration 69\t Training error: 0.0045404\n",
    "Iteration 70\t Training error: 0.00453159\n",
    "Iteration 71\t Training error: 0.0045232\n",
    "Iteration 72\t Training error: 0.00451522\n",
    "Iteration 73\t Training error: 0.00450765\n",
    "Iteration 74\t Training error: 0.00450049\n",
    "Iteration 75\t Training error: 0.00449372\n",
    "Iteration 76\t Training error: 0.00448735\n",
    "Iteration 77\t Training error: 0.00448136\n",
    "Iteration 78\t Training error: 0.00447575\n",
    "Iteration 79\t Training error: 0.0044705\n",
    "Iteration 80\t Training error: 0.0044656\n",
    "Iteration 81\t Training error: 0.00446104\n",
    "Iteration 82\t Training error: 0.00445681\n",
    "Iteration 83\t Training error: 0.00445289\n",
    "Iteration 84\t Training error: 0.00444925\n",
    "Iteration 85\t Training error: 0.0044459\n",
    "Iteration 86\t Training error: 0.0044428\n",
    "Iteration 87\t Training error: 0.00443995\n",
    "Iteration 88\t Training error: 0.00443733\n",
    "Iteration 89\t Training error: 0.00443492\n",
    "Iteration 90\t Training error: 0.0044327\n",
    "Iteration 91\t Training error: 0.00443067\n",
    "Iteration 92\t Training error: 0.0044288\n",
    "Iteration 93\t Training error: 0.00442708\n",
    "Iteration 94\t Training error: 0.00442549\n",
    "Iteration 95\t Training error: 0.00442403\n",
    "Iteration 96\t Training error: 0.00442268\n",
    "Iteration 97\t Training error: 0.00442143\n",
    "Iteration 98\t Training error: 0.00442027\n",
    "Iteration 99\t Training error: 0.00441918\n",
    "Iteration 100\t Training error: 0.00441816\n",
    "Iteration 101\t Training error: 0.0044172\n",
    "Iteration 102\t Training error: 0.00441629\n",
    "Iteration 103\t Training error: 0.00441542\n",
    "Iteration 104\t Training error: 0.00441458\n",
    "Iteration 105\t Training error: 0.00441377\n",
    "Iteration 106\t Training error: 0.00441298\n",
    "Iteration 107\t Training error: 0.00441221\n",
    "Iteration 108\t Training error: 0.00441144\n",
    "Iteration 109\t Training error: 0.00441068\n",
    "Iteration 110\t Training error: 0.00440991\n",
    "Iteration 111\t Training error: 0.00440913\n",
    "Iteration 112\t Training error: 0.00440835\n",
    "Iteration 113\t Training error: 0.00440754\n",
    "Iteration 114\t Training error: 0.00440672\n",
    "Iteration 115\t Training error: 0.00440587\n",
    "Iteration 116\t Training error: 0.00440499\n",
    "Iteration 117\t Training error: 0.00440408\n",
    "Iteration 118\t Training error: 0.00440313\n",
    "Iteration 119\t Training error: 0.00440215\n",
    "Iteration 120\t Training error: 0.00440112\n",
    "Iteration 121\t Training error: 0.00440004\n",
    "Iteration 122\t Training error: 0.00439892\n",
    "Iteration 123\t Training error: 0.00439774\n",
    "Iteration 124\t Training error: 0.0043965\n",
    "Iteration 125\t Training error: 0.0043952\n",
    "Iteration 126\t Training error: 0.00439384\n",
    "Iteration 127\t Training error: 0.00439241\n",
    "Iteration 128\t Training error: 0.00439091\n",
    "Iteration 129\t Training error: 0.00438934\n",
    "Iteration 130\t Training error: 0.00438769\n",
    "Iteration 131\t Training error: 0.00438595\n",
    "Iteration 132\t Training error: 0.00438413\n",
    "Iteration 133\t Training error: 0.00438223\n",
    "Iteration 134\t Training error: 0.00438023\n",
    "Iteration 135\t Training error: 0.00437813\n",
    "Iteration 136\t Training error: 0.00437594\n",
    "Iteration 137\t Training error: 0.00437364\n",
    "Iteration 138\t Training error: 0.00437124\n",
    "Iteration 139\t Training error: 0.00436873\n",
    "Iteration 140\t Training error: 0.00436611\n",
    "Iteration 141\t Training error: 0.00436338\n",
    "Iteration 142\t Training error: 0.00436054\n",
    "Iteration 143\t Training error: 0.00435757\n",
    "Iteration 144\t Training error: 0.00435449\n",
    "Iteration 145\t Training error: 0.00435129\n",
    "Iteration 146\t Training error: 0.00434797\n",
    "Iteration 147\t Training error: 0.00434453\n",
    "Iteration 148\t Training error: 0.00434098\n",
    "Iteration 149\t Training error: 0.0043373\n",
    "Iteration 150\t Training error: 0.00433351\n",
    "Iteration 151\t Training error: 0.00432961\n",
    "Iteration 152\t Training error: 0.0043256\n",
    "Iteration 153\t Training error: 0.00432147\n",
    "Iteration 154\t Training error: 0.00431725\n",
    "Iteration 155\t Training error: 0.00431293\n",
    "Iteration 156\t Training error: 0.00430851\n",
    "Iteration 157\t Training error: 0.00430401\n",
    "Iteration 158\t Training error: 0.00429943\n",
    "Iteration 159\t Training error: 0.00429477\n",
    "Iteration 160\t Training error: 0.00429005\n",
    "Iteration 161\t Training error: 0.00428526\n",
    "Iteration 162\t Training error: 0.00428042\n",
    "Iteration 163\t Training error: 0.00427553\n",
    "Iteration 164\t Training error: 0.0042706\n",
    "Iteration 165\t Training error: 0.00426564\n",
    "Iteration 166\t Training error: 0.00426065\n",
    "Iteration 167\t Training error: 0.00425564\n",
    "Iteration 168\t Training error: 0.00425061\n",
    "Iteration 169\t Training error: 0.00424557\n",
    "Iteration 170\t Training error: 0.00424052\n",
    "Iteration 171\t Training error: 0.00423547\n",
    "Iteration 172\t Training error: 0.00423042\n",
    "Iteration 173\t Training error: 0.00422537\n",
    "Iteration 174\t Training error: 0.00422033\n",
    "Iteration 175\t Training error: 0.0042153\n",
    "Iteration 176\t Training error: 0.00421028\n",
    "Iteration 177\t Training error: 0.00420527\n",
    "Iteration 178\t Training error: 0.00420028\n",
    "Iteration 179\t Training error: 0.00419529\n",
    "Iteration 180\t Training error: 0.00419032\n",
    "Iteration 181\t Training error: 0.00418536\n",
    "Iteration 182\t Training error: 0.00418041\n",
    "Iteration 183\t Training error: 0.00417547\n",
    "Iteration 184\t Training error: 0.00417054\n",
    "Iteration 185\t Training error: 0.00416561\n",
    "Iteration 186\t Training error: 0.0041607\n",
    "Iteration 187\t Training error: 0.00415579\n",
    "Iteration 188\t Training error: 0.00415089\n",
    "Iteration 189\t Training error: 0.00414598\n",
    "Iteration 190\t Training error: 0.00414109\n",
    "Iteration 191\t Training error: 0.00413619\n",
    "Iteration 192\t Training error: 0.00413129\n",
    "Iteration 193\t Training error: 0.00412639\n",
    "Iteration 194\t Training error: 0.00412149\n",
    "Iteration 195\t Training error: 0.00411659\n",
    "Iteration 196\t Training error: 0.00411168\n",
    "Iteration 197\t Training error: 0.00410677\n",
    "Iteration 198\t Training error: 0.00410186\n",
    "Iteration 199\t Training error: 0.00409694\n",
    "Iteration 200\t Training error: 0.00409202\n",
    "Iteration 201\t Training error: 0.00408709\n",
    "Iteration 202\t Training error: 0.00408216\n",
    "Iteration 203\t Training error: 0.00407723\n",
    "Iteration 204\t Training error: 0.00407229\n",
    "Iteration 205\t Training error: 0.00406735\n",
    "Iteration 206\t Training error: 0.00406241\n",
    "Iteration 207\t Training error: 0.00405747\n",
    "Iteration 208\t Training error: 0.00405253\n",
    "Iteration 209\t Training error: 0.0040476\n",
    "Iteration 210\t Training error: 0.00404266\n",
    "Iteration 211\t Training error: 0.00403774\n",
    "Iteration 212\t Training error: 0.00403281\n",
    "Iteration 213\t Training error: 0.0040279\n",
    "Iteration 214\t Training error: 0.004023\n",
    "Iteration 215\t Training error: 0.00401811\n",
    "Iteration 216\t Training error: 0.00401323\n",
    "Iteration 217\t Training error: 0.00400836\n",
    "Iteration 218\t Training error: 0.00400352\n",
    "Iteration 219\t Training error: 0.00399869\n",
    "Iteration 220\t Training error: 0.00399388\n",
    "Iteration 221\t Training error: 0.00398909\n",
    "Iteration 222\t Training error: 0.00398433\n",
    "Iteration 223\t Training error: 0.00397959\n",
    "Iteration 224\t Training error: 0.00397488\n",
    "Iteration 225\t Training error: 0.0039702\n",
    "Iteration 226\t Training error: 0.00396554\n",
    "Iteration 227\t Training error: 0.00396092\n",
    "Iteration 228\t Training error: 0.00395633\n",
    "Iteration 229\t Training error: 0.00395177\n",
    "Iteration 230\t Training error: 0.00394724\n",
    "Iteration 231\t Training error: 0.00394275\n",
    "Iteration 232\t Training error: 0.00393829\n",
    "Iteration 233\t Training error: 0.00393387\n",
    "Iteration 234\t Training error: 0.00392949\n",
    "Iteration 235\t Training error: 0.00392515\n",
    "Iteration 236\t Training error: 0.00392084\n",
    "Iteration 237\t Training error: 0.00391657\n",
    "Iteration 238\t Training error: 0.00391234\n",
    "Iteration 239\t Training error: 0.00390815\n",
    "Iteration 240\t Training error: 0.003904\n",
    "Iteration 241\t Training error: 0.00389988\n",
    "Iteration 242\t Training error: 0.00389581\n",
    "Iteration 243\t Training error: 0.00389177\n",
    "Iteration 244\t Training error: 0.00388777\n",
    "Iteration 245\t Training error: 0.00388382\n",
    "Iteration 246\t Training error: 0.0038799\n",
    "Iteration 247\t Training error: 0.00387601\n",
    "Iteration 248\t Training error: 0.00387217\n",
    "Iteration 249\t Training error: 0.00386836\n",
    "Iteration 250\t Training error: 0.00386459\n",
    "Iteration 251\t Training error: 0.00386086\n",
    "Iteration 252\t Training error: 0.00385716\n",
    "Iteration 253\t Training error: 0.00385349\n",
    "Iteration 254\t Training error: 0.00384987\n",
    "Iteration 255\t Training error: 0.00384627\n",
    "Iteration 256\t Training error: 0.00384271\n",
    "Iteration 257\t Training error: 0.00383918\n",
    "Iteration 258\t Training error: 0.00383569\n",
    "Iteration 259\t Training error: 0.00383222\n",
    "Iteration 260\t Training error: 0.00382879\n",
    "Iteration 261\t Training error: 0.00382539\n",
    "Iteration 262\t Training error: 0.00382202\n",
    "Iteration 263\t Training error: 0.00381868\n",
    "Iteration 264\t Training error: 0.00381536\n",
    "Iteration 265\t Training error: 0.00381208\n",
    "Iteration 266\t Training error: 0.00380882\n",
    "Iteration 267\t Training error: 0.00380559\n",
    "Iteration 268\t Training error: 0.00380238\n",
    "Iteration 269\t Training error: 0.0037992\n",
    "Iteration 270\t Training error: 0.00379604\n",
    "Iteration 271\t Training error: 0.00379291\n",
    "Iteration 272\t Training error: 0.00378981\n",
    "Iteration 273\t Training error: 0.00378672\n",
    "Iteration 274\t Training error: 0.00378366\n",
    "Iteration 275\t Training error: 0.00378062\n",
    "Iteration 276\t Training error: 0.0037776\n",
    "Iteration 277\t Training error: 0.0037746\n",
    "Iteration 278\t Training error: 0.00377162\n",
    "Iteration 279\t Training error: 0.00376867\n",
    "Iteration 280\t Training error: 0.00376573\n",
    "Iteration 281\t Training error: 0.00376281\n",
    "Iteration 282\t Training error: 0.0037599\n",
    "Iteration 283\t Training error: 0.00375702\n",
    "Iteration 284\t Training error: 0.00375415\n",
    "Iteration 285\t Training error: 0.0037513\n",
    "Iteration 286\t Training error: 0.00374847\n",
    "Iteration 287\t Training error: 0.00374565\n",
    "Iteration 288\t Training error: 0.00374284\n",
    "Iteration 289\t Training error: 0.00374005\n",
    "Iteration 290\t Training error: 0.00373728\n",
    "Iteration 291\t Training error: 0.00373452\n",
    "Iteration 292\t Training error: 0.00373177\n",
    "Iteration 293\t Training error: 0.00372904\n",
    "Iteration 294\t Training error: 0.00372632\n",
    "Iteration 295\t Training error: 0.00372361\n",
    "Iteration 296\t Training error: 0.00372091\n",
    "Iteration 297\t Training error: 0.00371823\n",
    "Iteration 298\t Training error: 0.00371556\n",
    "Iteration 299\t Training error: 0.0037129\n",
    "Iteration 300\t Training error: 0.00371025\n",
    "Iteration 301\t Training error: 0.00370761\n",
    "Iteration 302\t Training error: 0.00370498\n",
    "Iteration 303\t Training error: 0.00370236\n",
    "Iteration 304\t Training error: 0.00369975\n",
    "Iteration 305\t Training error: 0.00369714\n",
    "Iteration 306\t Training error: 0.00369455\n",
    "Iteration 307\t Training error: 0.00369197\n",
    "Iteration 308\t Training error: 0.0036894\n",
    "Iteration 309\t Training error: 0.00368683\n",
    "Iteration 310\t Training error: 0.00368427\n",
    "Iteration 311\t Training error: 0.00368172\n",
    "Iteration 312\t Training error: 0.00367918\n",
    "Iteration 313\t Training error: 0.00367665\n",
    "Iteration 314\t Training error: 0.00367412\n",
    "Iteration 315\t Training error: 0.0036716\n",
    "Iteration 316\t Training error: 0.00366909\n",
    "Iteration 317\t Training error: 0.00366658\n",
    "Iteration 318\t Training error: 0.00366408\n",
    "Iteration 319\t Training error: 0.00366159\n",
    "Iteration 320\t Training error: 0.00365911\n",
    "Iteration 321\t Training error: 0.00365663\n",
    "Iteration 322\t Training error: 0.00365415\n",
    "Iteration 323\t Training error: 0.00365168\n",
    "Iteration 324\t Training error: 0.00364922\n",
    "Iteration 325\t Training error: 0.00364676\n",
    "Iteration 326\t Training error: 0.00364431\n",
    "Iteration 327\t Training error: 0.00364187\n",
    "Iteration 328\t Training error: 0.00363943\n",
    "Iteration 329\t Training error: 0.00363699\n",
    "Iteration 330\t Training error: 0.00363456\n",
    "Iteration 331\t Training error: 0.00363213\n",
    "Iteration 332\t Training error: 0.00362971\n",
    "Iteration 333\t Training error: 0.0036273\n",
    "Iteration 334\t Training error: 0.00362489\n",
    "Iteration 335\t Training error: 0.00362248\n",
    "Iteration 336\t Training error: 0.00362008\n",
    "Iteration 337\t Training error: 0.00361768\n",
    "Iteration 338\t Training error: 0.00361528\n",
    "Iteration 339\t Training error: 0.0036129\n",
    "Iteration 340\t Training error: 0.00361051\n",
    "Iteration 341\t Training error: 0.00360813\n",
    "Iteration 342\t Training error: 0.00360575\n",
    "Iteration 343\t Training error: 0.00360338\n",
    "Iteration 344\t Training error: 0.00360101\n",
    "Iteration 345\t Training error: 0.00359864\n",
    "Iteration 346\t Training error: 0.00359628\n",
    "Iteration 347\t Training error: 0.00359392\n",
    "Iteration 348\t Training error: 0.00359156\n",
    "Iteration 349\t Training error: 0.00358921\n",
    "Iteration 350\t Training error: 0.00358686\n",
    "Iteration 351\t Training error: 0.00358451\n",
    "Iteration 352\t Training error: 0.00358217\n",
    "Iteration 353\t Training error: 0.00357983\n",
    "Iteration 354\t Training error: 0.0035775\n",
    "Iteration 355\t Training error: 0.00357516\n",
    "Iteration 356\t Training error: 0.00357283\n",
    "Iteration 357\t Training error: 0.00357051\n",
    "Iteration 358\t Training error: 0.00356818\n",
    "Iteration 359\t Training error: 0.00356586\n",
    "Iteration 360\t Training error: 0.00356354\n",
    "Iteration 361\t Training error: 0.00356123\n",
    "Iteration 362\t Training error: 0.00355891\n",
    "Iteration 363\t Training error: 0.0035566\n",
    "Iteration 364\t Training error: 0.00355429\n",
    "Iteration 365\t Training error: 0.00355199\n",
    "Iteration 366\t Training error: 0.00354969\n",
    "Iteration 367\t Training error: 0.00354739\n",
    "Iteration 368\t Training error: 0.00354509\n",
    "Iteration 369\t Training error: 0.00354279\n",
    "Iteration 370\t Training error: 0.0035405\n",
    "Iteration 371\t Training error: 0.00353821\n",
    "Iteration 372\t Training error: 0.00353592\n",
    "Iteration 373\t Training error: 0.00353363\n",
    "Iteration 374\t Training error: 0.00353135\n",
    "Iteration 375\t Training error: 0.00352906\n",
    "Iteration 376\t Training error: 0.00352678\n",
    "Iteration 377\t Training error: 0.0035245\n",
    "Iteration 378\t Training error: 0.00352223\n",
    "Iteration 379\t Training error: 0.00351995\n",
    "Iteration 380\t Training error: 0.00351768\n",
    "Iteration 381\t Training error: 0.00351541\n",
    "Iteration 382\t Training error: 0.00351314\n",
    "Iteration 383\t Training error: 0.00351087\n",
    "Iteration 384\t Training error: 0.00350861\n",
    "Iteration 385\t Training error: 0.00350634\n",
    "Iteration 386\t Training error: 0.00350408\n",
    "Iteration 387\t Training error: 0.00350182\n",
    "Iteration 388\t Training error: 0.00349956\n",
    "Iteration 389\t Training error: 0.00349731\n",
    "Iteration 390\t Training error: 0.00349505\n",
    "Iteration 391\t Training error: 0.0034928\n",
    "Iteration 392\t Training error: 0.00349055\n",
    "Iteration 393\t Training error: 0.0034883\n",
    "Iteration 394\t Training error: 0.00348605\n",
    "Iteration 395\t Training error: 0.0034838\n",
    "Iteration 396\t Training error: 0.00348156\n",
    "Iteration 397\t Training error: 0.00347931\n",
    "Iteration 398\t Training error: 0.00347707\n",
    "Iteration 399\t Training error: 0.00347483\n",
    "Iteration 400\t Training error: 0.00347259\n",
    "Iteration 401\t Training error: 0.00347036\n",
    "Iteration 402\t Training error: 0.00346812\n",
    "Iteration 403\t Training error: 0.00346588\n",
    "Iteration 404\t Training error: 0.00346365\n",
    "Iteration 405\t Training error: 0.00346142\n",
    "Iteration 406\t Training error: 0.00345919\n",
    "Iteration 407\t Training error: 0.00345696\n",
    "Iteration 408\t Training error: 0.00345474\n",
    "Iteration 409\t Training error: 0.00345251\n",
    "Iteration 410\t Training error: 0.00345029\n",
    "Iteration 411\t Training error: 0.00344806\n",
    "Iteration 412\t Training error: 0.00344584\n",
    "Iteration 413\t Training error: 0.00344362\n",
    "Iteration 414\t Training error: 0.00344141\n",
    "Iteration 415\t Training error: 0.00343919\n",
    "Iteration 416\t Training error: 0.00343697\n",
    "Iteration 417\t Training error: 0.00343476\n",
    "Iteration 418\t Training error: 0.00343255\n",
    "Iteration 419\t Training error: 0.00343034\n",
    "Iteration 420\t Training error: 0.00342813\n",
    "Iteration 421\t Training error: 0.00342592\n",
    "Iteration 422\t Training error: 0.00342372\n",
    "Iteration 423\t Training error: 0.00342151\n",
    "Iteration 424\t Training error: 0.00341931\n",
    "Iteration 425\t Training error: 0.00341711\n",
    "Iteration 426\t Training error: 0.00341491\n",
    "Iteration 427\t Training error: 0.00341271\n",
    "Iteration 428\t Training error: 0.00341052\n",
    "Iteration 429\t Training error: 0.00340832\n",
    "Iteration 430\t Training error: 0.00340613\n",
    "Iteration 431\t Training error: 0.00340394\n",
    "Iteration 432\t Training error: 0.00340175\n",
    "Iteration 433\t Training error: 0.00339956\n",
    "Iteration 434\t Training error: 0.00339737\n",
    "Iteration 435\t Training error: 0.00339519\n",
    "Iteration 436\t Training error: 0.00339301\n",
    "Iteration 437\t Training error: 0.00339083\n",
    "Iteration 438\t Training error: 0.00338865\n",
    "Iteration 439\t Training error: 0.00338647\n",
    "Iteration 440\t Training error: 0.00338429\n",
    "Iteration 441\t Training error: 0.00338212\n",
    "Iteration 442\t Training error: 0.00337995\n",
    "Iteration 443\t Training error: 0.00337778\n",
    "Iteration 444\t Training error: 0.00337561\n",
    "Iteration 445\t Training error: 0.00337344\n",
    "Iteration 446\t Training error: 0.00337128\n",
    "Iteration 447\t Training error: 0.00336911\n",
    "Iteration 448\t Training error: 0.00336695\n",
    "Iteration 449\t Training error: 0.00336479\n",
    "Iteration 450\t Training error: 0.00336264\n",
    "Iteration 451\t Training error: 0.00336048\n",
    "Iteration 452\t Training error: 0.00335833\n",
    "Iteration 453\t Training error: 0.00335618\n",
    "Iteration 454\t Training error: 0.00335403\n",
    "Iteration 455\t Training error: 0.00335188\n",
    "Iteration 456\t Training error: 0.00334974\n",
    "Iteration 457\t Training error: 0.0033476\n",
    "Iteration 458\t Training error: 0.00334546\n",
    "Iteration 459\t Training error: 0.00334332\n",
    "Iteration 460\t Training error: 0.00334118\n",
    "Iteration 461\t Training error: 0.00333905\n",
    "Iteration 462\t Training error: 0.00333692\n",
    "Iteration 463\t Training error: 0.00333479\n",
    "Iteration 464\t Training error: 0.00333266\n",
    "Iteration 465\t Training error: 0.00333054\n",
    "Iteration 466\t Training error: 0.00332842\n",
    "Iteration 467\t Training error: 0.0033263\n",
    "Iteration 468\t Training error: 0.00332418\n",
    "Iteration 469\t Training error: 0.00332206\n",
    "Iteration 470\t Training error: 0.00331995\n",
    "Iteration 471\t Training error: 0.00331784\n",
    "Iteration 472\t Training error: 0.00331573\n",
    "Iteration 473\t Training error: 0.00331363\n",
    "Iteration 474\t Training error: 0.00331153\n",
    "Iteration 475\t Training error: 0.00330943\n",
    "Iteration 476\t Training error: 0.00330733\n",
    "Iteration 477\t Training error: 0.00330524\n",
    "Iteration 478\t Training error: 0.00330315\n",
    "Iteration 479\t Training error: 0.00330106\n",
    "Iteration 480\t Training error: 0.00329897\n",
    "Iteration 481\t Training error: 0.00329689\n",
    "Iteration 482\t Training error: 0.00329481\n",
    "Iteration 483\t Training error: 0.00329273\n",
    "Iteration 484\t Training error: 0.00329066\n",
    "Iteration 485\t Training error: 0.00328859\n",
    "Iteration 486\t Training error: 0.00328652\n",
    "Iteration 487\t Training error: 0.00328446\n",
    "Iteration 488\t Training error: 0.0032824\n",
    "Iteration 489\t Training error: 0.00328034\n",
    "Iteration 490\t Training error: 0.00327828\n",
    "Iteration 491\t Training error: 0.00327623\n",
    "Iteration 492\t Training error: 0.00327418\n",
    "Iteration 493\t Training error: 0.00327214\n",
    "Iteration 494\t Training error: 0.00327009\n",
    "Iteration 495\t Training error: 0.00326806\n",
    "Iteration 496\t Training error: 0.00326602\n",
    "Iteration 497\t Training error: 0.00326399\n",
    "Iteration 498\t Training error: 0.00326196\n",
    "Iteration 499\t Training error: 0.00325994\n",
    "Iteration 500\t Training error: 0.00325792\n",
    "Iteration 501\t Training error: 0.0032559\n",
    "Iteration 502\t Training error: 0.00325389\n",
    "Iteration 503\t Training error: 0.00325188\n",
    "Iteration 504\t Training error: 0.00324987\n",
    "Iteration 505\t Training error: 0.00324787\n",
    "Iteration 506\t Training error: 0.00324587\n",
    "Iteration 507\t Training error: 0.00324388\n",
    "Iteration 508\t Training error: 0.00324189\n",
    "Iteration 509\t Training error: 0.0032399\n",
    "Iteration 510\t Training error: 0.00323792\n",
    "Iteration 511\t Training error: 0.00323594\n",
    "Iteration 512\t Training error: 0.00323397\n",
    "Iteration 513\t Training error: 0.003232\n",
    "Iteration 514\t Training error: 0.00323003\n",
    "Iteration 515\t Training error: 0.00322807\n",
    "Iteration 516\t Training error: 0.00322612\n",
    "Iteration 517\t Training error: 0.00322416\n",
    "Iteration 518\t Training error: 0.00322221\n",
    "Iteration 519\t Training error: 0.00322027\n",
    "Iteration 520\t Training error: 0.00321833\n",
    "Iteration 521\t Training error: 0.0032164\n",
    "Iteration 522\t Training error: 0.00321447\n",
    "Iteration 523\t Training error: 0.00321254\n",
    "Iteration 524\t Training error: 0.00321062\n",
    "Iteration 525\t Training error: 0.00320871\n",
    "Iteration 526\t Training error: 0.0032068\n",
    "Iteration 527\t Training error: 0.00320489\n",
    "Iteration 528\t Training error: 0.00320299\n",
    "Iteration 529\t Training error: 0.00320109\n",
    "Iteration 530\t Training error: 0.0031992\n",
    "Iteration 531\t Training error: 0.00319732\n",
    "Iteration 532\t Training error: 0.00319543\n",
    "Iteration 533\t Training error: 0.00319356\n",
    "Iteration 534\t Training error: 0.00319169\n",
    "Iteration 535\t Training error: 0.00318982\n",
    "Iteration 536\t Training error: 0.00318796\n",
    "Iteration 537\t Training error: 0.0031861\n",
    "Iteration 538\t Training error: 0.00318425\n",
    "Iteration 539\t Training error: 0.00318241\n",
    "Iteration 540\t Training error: 0.00318057\n",
    "Iteration 541\t Training error: 0.00317873\n",
    "Iteration 542\t Training error: 0.0031769\n",
    "Iteration 543\t Training error: 0.00317508\n",
    "Iteration 544\t Training error: 0.00317326\n",
    "Iteration 545\t Training error: 0.00317144\n",
    "Iteration 546\t Training error: 0.00316964\n",
    "Iteration 547\t Training error: 0.00316783\n",
    "Iteration 548\t Training error: 0.00316604\n",
    "Iteration 549\t Training error: 0.00316425\n",
    "Iteration 550\t Training error: 0.00316246\n",
    "Iteration 551\t Training error: 0.00316068\n",
    "Iteration 552\t Training error: 0.00315891\n",
    "Iteration 553\t Training error: 0.00315714\n",
    "Iteration 554\t Training error: 0.00315537\n",
    "Iteration 555\t Training error: 0.00315362\n",
    "Iteration 556\t Training error: 0.00315186\n",
    "Iteration 557\t Training error: 0.00315012\n",
    "Iteration 558\t Training error: 0.00314838\n",
    "Iteration 559\t Training error: 0.00314664\n",
    "Iteration 560\t Training error: 0.00314491\n",
    "Iteration 561\t Training error: 0.00314319\n",
    "Iteration 562\t Training error: 0.00314147\n",
    "Iteration 563\t Training error: 0.00313976\n",
    "Iteration 564\t Training error: 0.00313805\n",
    "Iteration 565\t Training error: 0.00313635\n",
    "Iteration 566\t Training error: 0.00313466\n",
    "Iteration 567\t Training error: 0.00313297\n",
    "Iteration 568\t Training error: 0.00313129\n",
    "Iteration 569\t Training error: 0.00312961\n",
    "Iteration 570\t Training error: 0.00312794\n",
    "Iteration 571\t Training error: 0.00312628\n",
    "Iteration 572\t Training error: 0.00312462\n",
    "Iteration 573\t Training error: 0.00312297\n",
    "Iteration 574\t Training error: 0.00312132\n",
    "Iteration 575\t Training error: 0.00311968\n",
    "Iteration 576\t Training error: 0.00311804\n",
    "Iteration 577\t Training error: 0.00311641\n",
    "Iteration 578\t Training error: 0.00311479\n",
    "Iteration 579\t Training error: 0.00311317\n",
    "Iteration 580\t Training error: 0.00311156\n",
    "Iteration 581\t Training error: 0.00310995\n",
    "Iteration 582\t Training error: 0.00310835\n",
    "Iteration 583\t Training error: 0.00310676\n",
    "Iteration 584\t Training error: 0.00310517\n",
    "Iteration 585\t Training error: 0.00310359\n",
    "Iteration 586\t Training error: 0.00310201\n",
    "Iteration 587\t Training error: 0.00310044\n",
    "Iteration 588\t Training error: 0.00309887\n",
    "Iteration 589\t Training error: 0.00309732\n",
    "Iteration 590\t Training error: 0.00309576\n",
    "Iteration 591\t Training error: 0.00309421\n",
    "Iteration 592\t Training error: 0.00309267\n",
    "Iteration 593\t Training error: 0.00309114\n",
    "Iteration 594\t Training error: 0.00308961\n",
    "Iteration 595\t Training error: 0.00308808\n",
    "Iteration 596\t Training error: 0.00308656\n",
    "Iteration 597\t Training error: 0.00308505\n",
    "Iteration 598\t Training error: 0.00308354\n",
    "Iteration 599\t Training error: 0.00308204\n",
    "Iteration 600\t Training error: 0.00308055\n",
    "Iteration 601\t Training error: 0.00307906\n",
    "Iteration 602\t Training error: 0.00307757\n",
    "Iteration 603\t Training error: 0.00307609\n",
    "Iteration 604\t Training error: 0.00307462\n",
    "Iteration 605\t Training error: 0.00307315\n",
    "Iteration 606\t Training error: 0.00307169\n",
    "Iteration 607\t Training error: 0.00307023\n",
    "Iteration 608\t Training error: 0.00306878\n",
    "Iteration 609\t Training error: 0.00306734\n",
    "Iteration 610\t Training error: 0.0030659\n",
    "Iteration 611\t Training error: 0.00306446\n",
    "Iteration 612\t Training error: 0.00306303\n",
    "Iteration 613\t Training error: 0.00306161\n",
    "Iteration 614\t Training error: 0.00306019\n",
    "Iteration 615\t Training error: 0.00305878\n",
    "Iteration 616\t Training error: 0.00305737\n",
    "Iteration 617\t Training error: 0.00305597\n",
    "Iteration 618\t Training error: 0.00305457\n",
    "Iteration 619\t Training error: 0.00305318\n",
    "Iteration 620\t Training error: 0.0030518\n",
    "Iteration 621\t Training error: 0.00305042\n",
    "Iteration 622\t Training error: 0.00304904\n",
    "Iteration 623\t Training error: 0.00304767\n",
    "Iteration 624\t Training error: 0.0030463\n",
    "Iteration 625\t Training error: 0.00304494\n",
    "Iteration 626\t Training error: 0.00304359\n",
    "Iteration 627\t Training error: 0.00304224\n",
    "Iteration 628\t Training error: 0.0030409\n",
    "Iteration 629\t Training error: 0.00303956\n",
    "Iteration 630\t Training error: 0.00303822\n",
    "Iteration 631\t Training error: 0.00303689\n",
    "Iteration 632\t Training error: 0.00303557\n",
    "Iteration 633\t Training error: 0.00303425\n",
    "Iteration 634\t Training error: 0.00303293\n",
    "Iteration 635\t Training error: 0.00303162\n",
    "Iteration 636\t Training error: 0.00303032\n",
    "Iteration 637\t Training error: 0.00302902\n",
    "Iteration 638\t Training error: 0.00302772\n",
    "Iteration 639\t Training error: 0.00302643\n",
    "Iteration 640\t Training error: 0.00302515\n",
    "Iteration 641\t Training error: 0.00302387\n",
    "Iteration 642\t Training error: 0.00302259\n",
    "Iteration 643\t Training error: 0.00302132\n",
    "Iteration 644\t Training error: 0.00302005\n",
    "Iteration 645\t Training error: 0.00301879\n",
    "Iteration 646\t Training error: 0.00301753\n",
    "Iteration 647\t Training error: 0.00301628\n",
    "Iteration 648\t Training error: 0.00301503\n",
    "Iteration 649\t Training error: 0.00301379\n",
    "Iteration 650\t Training error: 0.00301255\n",
    "Iteration 651\t Training error: 0.00301132\n",
    "Iteration 652\t Training error: 0.00301009\n",
    "Iteration 653\t Training error: 0.00300886\n",
    "Iteration 654\t Training error: 0.00300764\n",
    "Iteration 655\t Training error: 0.00300642\n",
    "Iteration 656\t Training error: 0.00300521\n",
    "Iteration 657\t Training error: 0.003004\n",
    "Iteration 658\t Training error: 0.0030028\n",
    "Iteration 659\t Training error: 0.0030016\n",
    "Iteration 660\t Training error: 0.00300041\n",
    "Iteration 661\t Training error: 0.00299922\n",
    "Iteration 662\t Training error: 0.00299803\n",
    "Iteration 663\t Training error: 0.00299685\n",
    "Iteration 664\t Training error: 0.00299567\n",
    "Iteration 665\t Training error: 0.0029945\n",
    "Iteration 666\t Training error: 0.00299333\n",
    "Iteration 667\t Training error: 0.00299216\n",
    "Iteration 668\t Training error: 0.002991\n",
    "Iteration 669\t Training error: 0.00298984\n",
    "Iteration 670\t Training error: 0.00298869\n",
    "Iteration 671\t Training error: 0.00298754\n",
    "Iteration 672\t Training error: 0.00298639\n",
    "Iteration 673\t Training error: 0.00298525\n",
    "Iteration 674\t Training error: 0.00298412\n",
    "Iteration 675\t Training error: 0.00298298\n",
    "Iteration 676\t Training error: 0.00298185\n",
    "Iteration 677\t Training error: 0.00298073\n",
    "Iteration 678\t Training error: 0.00297961\n",
    "Iteration 679\t Training error: 0.00297849\n",
    "Iteration 680\t Training error: 0.00297738\n",
    "Iteration 681\t Training error: 0.00297627\n",
    "Iteration 682\t Training error: 0.00297516\n",
    "Iteration 683\t Training error: 0.00297406\n",
    "Iteration 684\t Training error: 0.00297296\n",
    "Iteration 685\t Training error: 0.00297186\n",
    "Iteration 686\t Training error: 0.00297077\n",
    "Iteration 687\t Training error: 0.00296968\n",
    "Iteration 688\t Training error: 0.0029686\n",
    "Iteration 689\t Training error: 0.00296752\n",
    "Iteration 690\t Training error: 0.00296644\n",
    "Iteration 691\t Training error: 0.00296537\n",
    "Iteration 692\t Training error: 0.0029643\n",
    "Iteration 693\t Training error: 0.00296324\n",
    "Iteration 694\t Training error: 0.00296217\n",
    "Iteration 695\t Training error: 0.00296111\n",
    "Iteration 696\t Training error: 0.00296006\n",
    "Iteration 697\t Training error: 0.00295901\n",
    "Iteration 698\t Training error: 0.00295796\n",
    "Iteration 699\t Training error: 0.00295691\n",
    "Iteration 700\t Training error: 0.00295587\n",
    "Iteration 701\t Training error: 0.00295484\n",
    "Iteration 702\t Training error: 0.0029538\n",
    "Iteration 703\t Training error: 0.00295277\n",
    "Iteration 704\t Training error: 0.00295174\n",
    "Iteration 705\t Training error: 0.00295072\n",
    "Iteration 706\t Training error: 0.0029497\n",
    "Iteration 707\t Training error: 0.00294868\n",
    "Iteration 708\t Training error: 0.00294766\n",
    "Iteration 709\t Training error: 0.00294665\n",
    "Iteration 710\t Training error: 0.00294564\n",
    "Iteration 711\t Training error: 0.00294464\n",
    "Iteration 712\t Training error: 0.00294364\n",
    "Iteration 713\t Training error: 0.00294264\n",
    "Iteration 714\t Training error: 0.00294164\n",
    "Iteration 715\t Training error: 0.00294065\n",
    "Iteration 716\t Training error: 0.00293966\n",
    "Iteration 717\t Training error: 0.00293868\n",
    "Iteration 718\t Training error: 0.0029377\n",
    "Iteration 719\t Training error: 0.00293672\n",
    "Iteration 720\t Training error: 0.00293574\n",
    "Iteration 721\t Training error: 0.00293477\n",
    "Iteration 722\t Training error: 0.0029338\n",
    "Iteration 723\t Training error: 0.00293283\n",
    "Iteration 724\t Training error: 0.00293186\n",
    "Iteration 725\t Training error: 0.0029309\n",
    "Iteration 726\t Training error: 0.00292995\n",
    "Iteration 727\t Training error: 0.00292899\n",
    "Iteration 728\t Training error: 0.00292804\n",
    "Iteration 729\t Training error: 0.00292709\n",
    "Iteration 730\t Training error: 0.00292614\n",
    "Iteration 731\t Training error: 0.0029252\n",
    "Iteration 732\t Training error: 0.00292426\n",
    "Iteration 733\t Training error: 0.00292332\n",
    "Iteration 734\t Training error: 0.00292238\n",
    "Iteration 735\t Training error: 0.00292145\n",
    "Iteration 736\t Training error: 0.00292052\n",
    "Iteration 737\t Training error: 0.0029196\n",
    "Iteration 738\t Training error: 0.00291867\n",
    "Iteration 739\t Training error: 0.00291775\n",
    "Iteration 740\t Training error: 0.00291683\n",
    "Iteration 741\t Training error: 0.00291592\n",
    "Iteration 742\t Training error: 0.00291501\n",
    "Iteration 743\t Training error: 0.0029141\n",
    "Iteration 744\t Training error: 0.00291319\n",
    "Iteration 745\t Training error: 0.00291228\n",
    "Iteration 746\t Training error: 0.00291138\n",
    "Iteration 747\t Training error: 0.00291048\n",
    "Iteration 748\t Training error: 0.00290959\n",
    "Iteration 749\t Training error: 0.00290869\n",
    "Iteration 750\t Training error: 0.0029078\n",
    "Iteration 751\t Training error: 0.00290691\n",
    "Iteration 752\t Training error: 0.00290603\n",
    "Iteration 753\t Training error: 0.00290514\n",
    "Iteration 754\t Training error: 0.00290426\n",
    "Iteration 755\t Training error: 0.00290338\n",
    "Iteration 756\t Training error: 0.00290251\n",
    "Iteration 757\t Training error: 0.00290163\n",
    "Iteration 758\t Training error: 0.00290076\n",
    "Iteration 759\t Training error: 0.00289989\n",
    "Iteration 760\t Training error: 0.00289903\n",
    "Iteration 761\t Training error: 0.00289817\n",
    "Iteration 762\t Training error: 0.0028973\n",
    "Iteration 763\t Training error: 0.00289645\n",
    "Iteration 764\t Training error: 0.00289559\n",
    "Iteration 765\t Training error: 0.00289474\n",
    "Iteration 766\t Training error: 0.00289389\n",
    "Iteration 767\t Training error: 0.00289304\n",
    "Iteration 768\t Training error: 0.00289219\n",
    "Iteration 769\t Training error: 0.00289135\n",
    "Iteration 770\t Training error: 0.0028905\n",
    "Iteration 771\t Training error: 0.00288966\n",
    "Iteration 772\t Training error: 0.00288883\n",
    "Iteration 773\t Training error: 0.00288799\n",
    "Iteration 774\t Training error: 0.00288716\n",
    "Iteration 775\t Training error: 0.00288633\n",
    "Iteration 776\t Training error: 0.0028855\n",
    "Iteration 777\t Training error: 0.00288468\n",
    "Iteration 778\t Training error: 0.00288385\n",
    "Iteration 779\t Training error: 0.00288303\n",
    "Iteration 780\t Training error: 0.00288221\n",
    "Iteration 781\t Training error: 0.0028814\n",
    "Iteration 782\t Training error: 0.00288058\n",
    "Iteration 783\t Training error: 0.00287977\n",
    "Iteration 784\t Training error: 0.00287896\n",
    "Iteration 785\t Training error: 0.00287815\n",
    "Iteration 786\t Training error: 0.00287735\n",
    "Iteration 787\t Training error: 0.00287654\n",
    "Iteration 788\t Training error: 0.00287574\n",
    "Iteration 789\t Training error: 0.00287494\n",
    "Iteration 790\t Training error: 0.00287415\n",
    "Iteration 791\t Training error: 0.00287335\n",
    "Iteration 792\t Training error: 0.00287256\n",
    "Iteration 793\t Training error: 0.00287177\n",
    "Iteration 794\t Training error: 0.00287098\n",
    "Iteration 795\t Training error: 0.00287019\n",
    "Iteration 796\t Training error: 0.00286941\n",
    "Iteration 797\t Training error: 0.00286862\n",
    "Iteration 798\t Training error: 0.00286784\n",
    "Iteration 799\t Training error: 0.00286706\n",
    "Iteration 800\t Training error: 0.00286629\n",
    "Iteration 801\t Training error: 0.00286551\n",
    "Iteration 802\t Training error: 0.00286474\n",
    "Iteration 803\t Training error: 0.00286397\n",
    "Iteration 804\t Training error: 0.0028632\n",
    "Iteration 805\t Training error: 0.00286244\n",
    "Iteration 806\t Training error: 0.00286167\n",
    "Iteration 807\t Training error: 0.00286091\n",
    "Iteration 808\t Training error: 0.00286015\n",
    "Iteration 809\t Training error: 0.00285939\n",
    "Iteration 810\t Training error: 0.00285863\n",
    "Iteration 811\t Training error: 0.00285788\n",
    "Iteration 812\t Training error: 0.00285712\n",
    "Iteration 813\t Training error: 0.00285637\n",
    "Iteration 814\t Training error: 0.00285562\n",
    "Iteration 815\t Training error: 0.00285488\n",
    "Iteration 816\t Training error: 0.00285413\n",
    "Iteration 817\t Training error: 0.00285339\n",
    "Iteration 818\t Training error: 0.00285264\n",
    "Iteration 819\t Training error: 0.0028519\n",
    "Iteration 820\t Training error: 0.00285117\n",
    "Iteration 821\t Training error: 0.00285043\n",
    "Iteration 822\t Training error: 0.00284969\n",
    "Iteration 823\t Training error: 0.00284896\n",
    "Iteration 824\t Training error: 0.00284823\n",
    "Iteration 825\t Training error: 0.0028475\n",
    "Iteration 826\t Training error: 0.00284677\n",
    "Iteration 827\t Training error: 0.00284605\n",
    "Iteration 828\t Training error: 0.00284532\n",
    "Iteration 829\t Training error: 0.0028446\n",
    "Iteration 830\t Training error: 0.00284388\n",
    "Iteration 831\t Training error: 0.00284316\n",
    "Iteration 832\t Training error: 0.00284245\n",
    "Iteration 833\t Training error: 0.00284173\n",
    "Iteration 834\t Training error: 0.00284102\n",
    "Iteration 835\t Training error: 0.00284031\n",
    "Iteration 836\t Training error: 0.0028396\n",
    "Iteration 837\t Training error: 0.00283889\n",
    "Iteration 838\t Training error: 0.00283818\n",
    "Iteration 839\t Training error: 0.00283748\n",
    "Iteration 840\t Training error: 0.00283677\n",
    "Iteration 841\t Training error: 0.00283607\n",
    "Iteration 842\t Training error: 0.00283537\n",
    "Iteration 843\t Training error: 0.00283467\n",
    "Iteration 844\t Training error: 0.00283398\n",
    "Iteration 845\t Training error: 0.00283328\n",
    "Iteration 846\t Training error: 0.00283259\n",
    "Iteration 847\t Training error: 0.0028319\n",
    "Iteration 848\t Training error: 0.00283121\n",
    "Iteration 849\t Training error: 0.00283052\n",
    "Iteration 850\t Training error: 0.00282983\n",
    "Iteration 851\t Training error: 0.00282914\n",
    "Iteration 852\t Training error: 0.00282846\n",
    "Iteration 853\t Training error: 0.00282778\n",
    "Iteration 854\t Training error: 0.0028271\n",
    "Iteration 855\t Training error: 0.00282642\n",
    "Iteration 856\t Training error: 0.00282574\n",
    "Iteration 857\t Training error: 0.00282507\n",
    "Iteration 858\t Training error: 0.00282439\n",
    "Iteration 859\t Training error: 0.00282372\n",
    "Iteration 860\t Training error: 0.00282305\n",
    "Iteration 861\t Training error: 0.00282238\n",
    "Iteration 862\t Training error: 0.00282171\n",
    "Iteration 863\t Training error: 0.00282104\n",
    "Iteration 864\t Training error: 0.00282038\n",
    "Iteration 865\t Training error: 0.00281971\n",
    "Iteration 866\t Training error: 0.00281905\n",
    "Iteration 867\t Training error: 0.00281839\n",
    "Iteration 868\t Training error: 0.00281773\n",
    "Iteration 869\t Training error: 0.00281708\n",
    "Iteration 870\t Training error: 0.00281642\n",
    "Iteration 871\t Training error: 0.00281576\n",
    "Iteration 872\t Training error: 0.00281511\n",
    "Iteration 873\t Training error: 0.00281446\n",
    "Iteration 874\t Training error: 0.00281381\n",
    "Iteration 875\t Training error: 0.00281316\n",
    "Iteration 876\t Training error: 0.00281251\n",
    "Iteration 877\t Training error: 0.00281187\n",
    "Iteration 878\t Training error: 0.00281122\n",
    "Iteration 879\t Training error: 0.00281058\n",
    "Iteration 880\t Training error: 0.00280994\n",
    "Iteration 881\t Training error: 0.0028093\n",
    "Iteration 882\t Training error: 0.00280866\n",
    "Iteration 883\t Training error: 0.00280802\n",
    "Iteration 884\t Training error: 0.00280739\n",
    "Iteration 885\t Training error: 0.00280675\n",
    "Iteration 886\t Training error: 0.00280612\n",
    "Iteration 887\t Training error: 0.00280549\n",
    "Iteration 888\t Training error: 0.00280486\n",
    "Iteration 889\t Training error: 0.00280423\n",
    "Iteration 890\t Training error: 0.0028036\n",
    "Iteration 891\t Training error: 0.00280297\n",
    "Iteration 892\t Training error: 0.00280235\n",
    "Iteration 893\t Training error: 0.00280172\n",
    "Iteration 894\t Training error: 0.0028011\n",
    "Iteration 895\t Training error: 0.00280048\n",
    "Iteration 896\t Training error: 0.00279986\n",
    "Iteration 897\t Training error: 0.00279924\n",
    "Iteration 898\t Training error: 0.00279862\n",
    "Iteration 899\t Training error: 0.00279801\n",
    "Iteration 900\t Training error: 0.00279739\n",
    "Iteration 901\t Training error: 0.00279678\n",
    "Iteration 902\t Training error: 0.00279617\n",
    "Iteration 903\t Training error: 0.00279556\n",
    "Iteration 904\t Training error: 0.00279495\n",
    "Iteration 905\t Training error: 0.00279434\n",
    "Iteration 906\t Training error: 0.00279374\n",
    "Iteration 907\t Training error: 0.00279313\n",
    "Iteration 908\t Training error: 0.00279253\n",
    "Iteration 909\t Training error: 0.00279192\n",
    "Iteration 910\t Training error: 0.00279132\n",
    "Iteration 911\t Training error: 0.00279072\n",
    "Iteration 912\t Training error: 0.00279012\n",
    "Iteration 913\t Training error: 0.00278952\n",
    "Iteration 914\t Training error: 0.00278893\n",
    "Iteration 915\t Training error: 0.00278833\n",
    "Iteration 916\t Training error: 0.00278774\n",
    "Iteration 917\t Training error: 0.00278714\n",
    "Iteration 918\t Training error: 0.00278655\n",
    "Iteration 919\t Training error: 0.00278596\n",
    "Iteration 920\t Training error: 0.00278537\n",
    "Iteration 921\t Training error: 0.00278478\n",
    "Iteration 922\t Training error: 0.0027842\n",
    "Iteration 923\t Training error: 0.00278361\n",
    "Iteration 924\t Training error: 0.00278302\n",
    "Iteration 925\t Training error: 0.00278244\n",
    "Iteration 926\t Training error: 0.00278186\n",
    "Iteration 927\t Training error: 0.00278128\n",
    "Iteration 928\t Training error: 0.0027807\n",
    "Iteration 929\t Training error: 0.00278012\n",
    "Iteration 930\t Training error: 0.00277954\n",
    "Iteration 931\t Training error: 0.00277896\n",
    "Iteration 932\t Training error: 0.00277839\n",
    "Iteration 933\t Training error: 0.00277781\n",
    "Iteration 934\t Training error: 0.00277724\n",
    "Iteration 935\t Training error: 0.00277667\n",
    "Iteration 936\t Training error: 0.00277609\n",
    "Iteration 937\t Training error: 0.00277552\n",
    "Iteration 938\t Training error: 0.00277495\n",
    "Iteration 939\t Training error: 0.00277439\n",
    "Iteration 940\t Training error: 0.00277382\n",
    "Iteration 941\t Training error: 0.00277325\n",
    "Iteration 942\t Training error: 0.00277269\n",
    "Iteration 943\t Training error: 0.00277212\n",
    "Iteration 944\t Training error: 0.00277156\n",
    "Iteration 945\t Training error: 0.002771\n",
    "Iteration 946\t Training error: 0.00277044\n",
    "Iteration 947\t Training error: 0.00276988\n",
    "Iteration 948\t Training error: 0.00276932\n",
    "Iteration 949\t Training error: 0.00276876\n",
    "Iteration 950\t Training error: 0.00276821\n",
    "Iteration 951\t Training error: 0.00276765\n",
    "Iteration 952\t Training error: 0.0027671\n",
    "Iteration 953\t Training error: 0.00276654\n",
    "Iteration 954\t Training error: 0.00276599\n",
    "Iteration 955\t Training error: 0.00276544\n",
    "Iteration 956\t Training error: 0.00276489\n",
    "Iteration 957\t Training error: 0.00276434\n",
    "Iteration 958\t Training error: 0.00276379\n",
    "Iteration 959\t Training error: 0.00276324\n",
    "Iteration 960\t Training error: 0.00276269\n",
    "Iteration 961\t Training error: 0.00276215\n",
    "Iteration 962\t Training error: 0.0027616\n",
    "Iteration 963\t Training error: 0.00276106\n",
    "Iteration 964\t Training error: 0.00276051\n",
    "Iteration 965\t Training error: 0.00275997\n",
    "Iteration 966\t Training error: 0.00275943\n",
    "Iteration 967\t Training error: 0.00275889\n",
    "Iteration 968\t Training error: 0.00275835\n",
    "Iteration 969\t Training error: 0.00275781\n",
    "Iteration 970\t Training error: 0.00275727\n",
    "Iteration 971\t Training error: 0.00275673\n",
    "Iteration 972\t Training error: 0.0027562\n",
    "Iteration 973\t Training error: 0.00275566\n",
    "Iteration 974\t Training error: 0.00275513\n",
    "Iteration 975\t Training error: 0.00275459\n",
    "Iteration 976\t Training error: 0.00275406\n",
    "Iteration 977\t Training error: 0.00275353\n",
    "Iteration 978\t Training error: 0.002753\n",
    "Iteration 979\t Training error: 0.00275247\n",
    "Iteration 980\t Training error: 0.00275194\n",
    "Iteration 981\t Training error: 0.00275141\n",
    "Iteration 982\t Training error: 0.00275088\n",
    "Iteration 983\t Training error: 0.00275036\n",
    "Iteration 984\t Training error: 0.00274983\n",
    "Iteration 985\t Training error: 0.0027493\n",
    "Iteration 986\t Training error: 0.00274878\n",
    "Iteration 987\t Training error: 0.00274826\n",
    "Iteration 988\t Training error: 0.00274773\n",
    "Iteration 989\t Training error: 0.00274721\n",
    "Iteration 990\t Training error: 0.00274669\n",
    "Iteration 991\t Training error: 0.00274617\n",
    "Iteration 992\t Training error: 0.00274565\n",
    "Iteration 993\t Training error: 0.00274513\n",
    "Iteration 994\t Training error: 0.00274461\n",
    "Iteration 995\t Training error: 0.00274409\n",
    "Iteration 996\t Training error: 0.00274358\n",
    "Iteration 997\t Training error: 0.00274306\n",
    "Iteration 998\t Training error: 0.00274255\n",
    "Iteration 999\t Training error: 0.00274203\n",
    "Iteration 1000\t Training error: 0.00274152\n",
    "Iteration 1001\t Training error: 0.002741\n",
    "Iteration 1002\t Training error: 0.00274049\n",
    "Iteration 1003\t Training error: 0.00273998\n",
    "Iteration 1004\t Training error: 0.00273947\n",
    "Iteration 1005\t Training error: 0.00273896\n",
    "Iteration 1006\t Training error: 0.00273845\n",
    "Iteration 1007\t Training error: 0.00273794\n",
    "Iteration 1008\t Training error: 0.00273743\n",
    "Iteration 1009\t Training error: 0.00273692\n",
    "Iteration 1010\t Training error: 0.00273642\n",
    "Iteration 1011\t Training error: 0.00273591\n",
    "Iteration 1012\t Training error: 0.00273541\n",
    "Iteration 1013\t Training error: 0.0027349\n",
    "Iteration 1014\t Training error: 0.0027344\n",
    "Iteration 1015\t Training error: 0.00273389\n",
    "Iteration 1016\t Training error: 0.00273339\n",
    "Iteration 1017\t Training error: 0.00273289\n",
    "Iteration 1018\t Training error: 0.00273239\n",
    "Iteration 1019\t Training error: 0.00273189\n",
    "Iteration 1020\t Training error: 0.00273139\n",
    "Iteration 1021\t Training error: 0.00273089\n",
    "Iteration 1022\t Training error: 0.00273039\n",
    "Iteration 1023\t Training error: 0.00272989\n",
    "Iteration 1024\t Training error: 0.00272939\n",
    "Iteration 1025\t Training error: 0.00272889\n",
    "Iteration 1026\t Training error: 0.0027284\n",
    "Iteration 1027\t Training error: 0.0027279\n",
    "Iteration 1028\t Training error: 0.00272741\n",
    "Iteration 1029\t Training error: 0.00272691\n",
    "Iteration 1030\t Training error: 0.00272642\n",
    "Iteration 1031\t Training error: 0.00272592\n",
    "Iteration 1032\t Training error: 0.00272543\n",
    "Iteration 1033\t Training error: 0.00272494\n",
    "Iteration 1034\t Training error: 0.00272445\n",
    "Iteration 1035\t Training error: 0.00272396\n",
    "Iteration 1036\t Training error: 0.00272346\n",
    "Iteration 1037\t Training error: 0.00272297\n",
    "Iteration 1038\t Training error: 0.00272249\n",
    "Iteration 1039\t Training error: 0.002722\n",
    "Iteration 1040\t Training error: 0.00272151\n",
    "Iteration 1041\t Training error: 0.00272102\n",
    "Iteration 1042\t Training error: 0.00272053\n",
    "Iteration 1043\t Training error: 0.00272005\n",
    "Iteration 1044\t Training error: 0.00271956\n",
    "Iteration 1045\t Training error: 0.00271908\n",
    "Iteration 1046\t Training error: 0.00271859\n",
    "Iteration 1047\t Training error: 0.00271811\n",
    "Iteration 1048\t Training error: 0.00271762\n",
    "Iteration 1049\t Training error: 0.00271714\n",
    "Iteration 1050\t Training error: 0.00271666\n",
    "Iteration 1051\t Training error: 0.00271617\n",
    "Iteration 1052\t Training error: 0.00271569\n",
    "Iteration 1053\t Training error: 0.00271521\n",
    "Iteration 1054\t Training error: 0.00271473\n",
    "Iteration 1055\t Training error: 0.00271425\n",
    "Iteration 1056\t Training error: 0.00271377\n",
    "Iteration 1057\t Training error: 0.00271329\n",
    "Iteration 1058\t Training error: 0.00271281\n",
    "Iteration 1059\t Training error: 0.00271234\n",
    "Iteration 1060\t Training error: 0.00271186\n",
    "Iteration 1061\t Training error: 0.00271138\n",
    "Iteration 1062\t Training error: 0.00271091\n",
    "Iteration 1063\t Training error: 0.00271043\n",
    "Iteration 1064\t Training error: 0.00270995\n",
    "Iteration 1065\t Training error: 0.00270948\n",
    "Iteration 1066\t Training error: 0.00270901\n",
    "Iteration 1067\t Training error: 0.00270853\n",
    "Iteration 1068\t Training error: 0.00270806\n",
    "Iteration 1069\t Training error: 0.00270759\n",
    "Iteration 1070\t Training error: 0.00270711\n",
    "Iteration 1071\t Training error: 0.00270664\n",
    "Iteration 1072\t Training error: 0.00270617\n",
    "Iteration 1073\t Training error: 0.0027057\n",
    "Iteration 1074\t Training error: 0.00270523\n",
    "Iteration 1075\t Training error: 0.00270476\n",
    "Iteration 1076\t Training error: 0.00270429\n",
    "Iteration 1077\t Training error: 0.00270382\n",
    "Iteration 1078\t Training error: 0.00270335\n",
    "Iteration 1079\t Training error: 0.00270288\n",
    "Iteration 1080\t Training error: 0.00270242\n",
    "Iteration 1081\t Training error: 0.00270195\n",
    "Iteration 1082\t Training error: 0.00270148\n",
    "Iteration 1083\t Training error: 0.00270102\n",
    "Iteration 1084\t Training error: 0.00270055\n",
    "Iteration 1085\t Training error: 0.00270009\n",
    "Iteration 1086\t Training error: 0.00269962\n",
    "Iteration 1087\t Training error: 0.00269916\n",
    "Iteration 1088\t Training error: 0.0026987\n",
    "Iteration 1089\t Training error: 0.00269823\n",
    "Iteration 1090\t Training error: 0.00269777\n",
    "Iteration 1091\t Training error: 0.00269731\n",
    "Iteration 1092\t Training error: 0.00269685\n",
    "Iteration 1093\t Training error: 0.00269639\n",
    "Iteration 1094\t Training error: 0.00269593\n",
    "Iteration 1095\t Training error: 0.00269547\n",
    "Iteration 1096\t Training error: 0.00269501\n",
    "Iteration 1097\t Training error: 0.00269455\n",
    "Iteration 1098\t Training error: 0.00269409\n",
    "Iteration 1099\t Training error: 0.00269363\n",
    "Iteration 1100\t Training error: 0.00269317\n",
    "Iteration 1101\t Training error: 0.00269272\n",
    "Iteration 1102\t Training error: 0.00269226\n",
    "Iteration 1103\t Training error: 0.0026918\n",
    "Iteration 1104\t Training error: 0.00269135\n",
    "Iteration 1105\t Training error: 0.00269089\n",
    "Iteration 1106\t Training error: 0.00269044\n",
    "Iteration 1107\t Training error: 0.00268998\n",
    "Iteration 1108\t Training error: 0.00268953\n",
    "Iteration 1109\t Training error: 0.00268907\n",
    "Iteration 1110\t Training error: 0.00268862\n",
    "Iteration 1111\t Training error: 0.00268817\n",
    "Iteration 1112\t Training error: 0.00268772\n",
    "Iteration 1113\t Training error: 0.00268727\n",
    "Iteration 1114\t Training error: 0.00268681\n",
    "Iteration 1115\t Training error: 0.00268636\n",
    "Iteration 1116\t Training error: 0.00268591\n",
    "Iteration 1117\t Training error: 0.00268546\n",
    "Iteration 1118\t Training error: 0.00268501\n",
    "Iteration 1119\t Training error: 0.00268457\n",
    "Iteration 1120\t Training error: 0.00268412\n",
    "Iteration 1121\t Training error: 0.00268367\n",
    "Iteration 1122\t Training error: 0.00268322\n",
    "Iteration 1123\t Training error: 0.00268278\n",
    "Iteration 1124\t Training error: 0.00268233\n",
    "Iteration 1125\t Training error: 0.00268188\n",
    "Iteration 1126\t Training error: 0.00268144\n",
    "Iteration 1127\t Training error: 0.00268099\n",
    "Iteration 1128\t Training error: 0.00268055\n",
    "Iteration 1129\t Training error: 0.00268011\n",
    "Iteration 1130\t Training error: 0.00267966\n",
    "Iteration 1131\t Training error: 0.00267922\n",
    "Iteration 1132\t Training error: 0.00267878\n",
    "Iteration 1133\t Training error: 0.00267833\n",
    "Iteration 1134\t Training error: 0.00267789\n",
    "Iteration 1135\t Training error: 0.00267745\n",
    "Iteration 1136\t Training error: 0.00267701\n",
    "Iteration 1137\t Training error: 0.00267657\n",
    "Iteration 1138\t Training error: 0.00267613\n",
    "Iteration 1139\t Training error: 0.00267569\n",
    "Iteration 1140\t Training error: 0.00267525\n",
    "Iteration 1141\t Training error: 0.00267482\n",
    "Iteration 1142\t Training error: 0.00267438\n",
    "Iteration 1143\t Training error: 0.00267394\n",
    "Iteration 1144\t Training error: 0.00267351\n",
    "Iteration 1145\t Training error: 0.00267307\n",
    "Iteration 1146\t Training error: 0.00267263\n",
    "Iteration 1147\t Training error: 0.0026722\n",
    "Iteration 1148\t Training error: 0.00267176\n",
    "Iteration 1149\t Training error: 0.00267133\n",
    "Iteration 1150\t Training error: 0.0026709\n",
    "Iteration 1151\t Training error: 0.00267046\n",
    "Iteration 1152\t Training error: 0.00267003\n",
    "Iteration 1153\t Training error: 0.0026696\n",
    "Iteration 1154\t Training error: 0.00266917\n",
    "Iteration 1155\t Training error: 0.00266873\n",
    "Iteration 1156\t Training error: 0.0026683\n",
    "Iteration 1157\t Training error: 0.00266787\n",
    "Iteration 1158\t Training error: 0.00266744\n",
    "Iteration 1159\t Training error: 0.00266701\n",
    "Iteration 1160\t Training error: 0.00266659\n",
    "Iteration 1161\t Training error: 0.00266616\n",
    "Iteration 1162\t Training error: 0.00266573\n",
    "Iteration 1163\t Training error: 0.0026653\n",
    "Iteration 1164\t Training error: 0.00266488\n",
    "Iteration 1165\t Training error: 0.00266445\n",
    "Iteration 1166\t Training error: 0.00266402\n",
    "Iteration 1167\t Training error: 0.0026636\n",
    "Iteration 1168\t Training error: 0.00266317\n",
    "Iteration 1169\t Training error: 0.00266275\n",
    "Iteration 1170\t Training error: 0.00266233\n",
    "Iteration 1171\t Training error: 0.0026619\n",
    "Iteration 1172\t Training error: 0.00266148\n",
    "Iteration 1173\t Training error: 0.00266106\n",
    "Iteration 1174\t Training error: 0.00266064\n",
    "Iteration 1175\t Training error: 0.00266022\n",
    "Iteration 1176\t Training error: 0.00265979\n",
    "Iteration 1177\t Training error: 0.00265937\n",
    "Iteration 1178\t Training error: 0.00265895\n",
    "Iteration 1179\t Training error: 0.00265854\n",
    "Iteration 1180\t Training error: 0.00265812\n",
    "Iteration 1181\t Training error: 0.0026577\n",
    "Iteration 1182\t Training error: 0.00265728\n",
    "Iteration 1183\t Training error: 0.00265686\n",
    "Iteration 1184\t Training error: 0.00265645\n",
    "Iteration 1185\t Training error: 0.00265603\n",
    "Iteration 1186\t Training error: 0.00265562\n",
    "Iteration 1187\t Training error: 0.0026552\n",
    "Iteration 1188\t Training error: 0.00265479\n",
    "Iteration 1189\t Training error: 0.00265437\n",
    "Iteration 1190\t Training error: 0.00265396\n",
    "Iteration 1191\t Training error: 0.00265355\n",
    "Iteration 1192\t Training error: 0.00265313\n",
    "Iteration 1193\t Training error: 0.00265272\n",
    "Iteration 1194\t Training error: 0.00265231\n",
    "Iteration 1195\t Training error: 0.0026519\n",
    "Iteration 1196\t Training error: 0.00265149\n",
    "Iteration 1197\t Training error: 0.00265108\n",
    "Iteration 1198\t Training error: 0.00265067\n",
    "Iteration 1199\t Training error: 0.00265026\n",
    "Iteration 1200\t Training error: 0.00264985\n",
    "Iteration 1201\t Training error: 0.00264945\n",
    "Iteration 1202\t Training error: 0.00264904\n",
    "Iteration 1203\t Training error: 0.00264863\n",
    "Iteration 1204\t Training error: 0.00264823\n",
    "Iteration 1205\t Training error: 0.00264782\n",
    "Iteration 1206\t Training error: 0.00264742\n",
    "Iteration 1207\t Training error: 0.00264701\n",
    "Iteration 1208\t Training error: 0.00264661\n",
    "Iteration 1209\t Training error: 0.0026462\n",
    "Iteration 1210\t Training error: 0.0026458\n",
    "Iteration 1211\t Training error: 0.0026454\n",
    "Iteration 1212\t Training error: 0.002645\n",
    "Iteration 1213\t Training error: 0.0026446\n",
    "Iteration 1214\t Training error: 0.00264419\n",
    "Iteration 1215\t Training error: 0.00264379\n",
    "Iteration 1216\t Training error: 0.00264339\n",
    "Iteration 1217\t Training error: 0.002643\n",
    "Iteration 1218\t Training error: 0.0026426\n",
    "Iteration 1219\t Training error: 0.0026422\n",
    "Iteration 1220\t Training error: 0.0026418\n",
    "Iteration 1221\t Training error: 0.0026414\n",
    "Iteration 1222\t Training error: 0.00264101\n",
    "Iteration 1223\t Training error: 0.00264061\n",
    "Iteration 1224\t Training error: 0.00264022\n",
    "Iteration 1225\t Training error: 0.00263982\n",
    "Iteration 1226\t Training error: 0.00263943\n",
    "Iteration 1227\t Training error: 0.00263903\n",
    "Iteration 1228\t Training error: 0.00263864\n",
    "Iteration 1229\t Training error: 0.00263825\n",
    "Iteration 1230\t Training error: 0.00263785\n",
    "Iteration 1231\t Training error: 0.00263746\n",
    "Iteration 1232\t Training error: 0.00263707\n",
    "Iteration 1233\t Training error: 0.00263668\n",
    "Iteration 1234\t Training error: 0.00263629\n",
    "Iteration 1235\t Training error: 0.0026359\n",
    "Iteration 1236\t Training error: 0.00263551\n",
    "Iteration 1237\t Training error: 0.00263512\n",
    "Iteration 1238\t Training error: 0.00263473\n",
    "Iteration 1239\t Training error: 0.00263434\n",
    "Iteration 1240\t Training error: 0.00263396\n",
    "Iteration 1241\t Training error: 0.00263357\n",
    "Iteration 1242\t Training error: 0.00263318\n",
    "Iteration 1243\t Training error: 0.0026328\n",
    "Iteration 1244\t Training error: 0.00263241\n",
    "Iteration 1245\t Training error: 0.00263203\n",
    "Iteration 1246\t Training error: 0.00263164\n",
    "Iteration 1247\t Training error: 0.00263126\n",
    "Iteration 1248\t Training error: 0.00263088\n",
    "Iteration 1249\t Training error: 0.00263049\n",
    "Iteration 1250\t Training error: 0.00263011\n",
    "Iteration 1251\t Training error: 0.00262973\n",
    "Iteration 1252\t Training error: 0.00262935\n",
    "Iteration 1253\t Training error: 0.00262897\n",
    "Iteration 1254\t Training error: 0.00262859\n",
    "Iteration 1255\t Training error: 0.00262821\n",
    "Iteration 1256\t Training error: 0.00262783\n",
    "Iteration 1257\t Training error: 0.00262745\n",
    "Iteration 1258\t Training error: 0.00262707\n",
    "Iteration 1259\t Training error: 0.0026267\n",
    "Iteration 1260\t Training error: 0.00262632\n",
    "Iteration 1261\t Training error: 0.00262594\n",
    "Iteration 1262\t Training error: 0.00262557\n",
    "Iteration 1263\t Training error: 0.00262519\n",
    "Iteration 1264\t Training error: 0.00262482\n",
    "Iteration 1265\t Training error: 0.00262444\n",
    "Iteration 1266\t Training error: 0.00262407\n",
    "Iteration 1267\t Training error: 0.00262369\n",
    "Iteration 1268\t Training error: 0.00262332\n",
    "Iteration 1269\t Training error: 0.00262295\n",
    "Iteration 1270\t Training error: 0.00262258\n",
    "Iteration 1271\t Training error: 0.0026222\n",
    "Iteration 1272\t Training error: 0.00262183\n",
    "Iteration 1273\t Training error: 0.00262146\n",
    "Iteration 1274\t Training error: 0.00262109\n",
    "Iteration 1275\t Training error: 0.00262072\n",
    "Iteration 1276\t Training error: 0.00262035\n",
    "Iteration 1277\t Training error: 0.00261998\n",
    "Iteration 1278\t Training error: 0.00261961\n",
    "Iteration 1279\t Training error: 0.00261925\n",
    "Iteration 1280\t Training error: 0.00261888\n",
    "Iteration 1281\t Training error: 0.00261851\n",
    "Iteration 1282\t Training error: 0.00261815\n",
    "Iteration 1283\t Training error: 0.00261778\n",
    "Iteration 1284\t Training error: 0.00261741\n",
    "Iteration 1285\t Training error: 0.00261705\n",
    "Iteration 1286\t Training error: 0.00261669\n",
    "Iteration 1287\t Training error: 0.00261632\n",
    "Iteration 1288\t Training error: 0.00261596\n",
    "Iteration 1289\t Training error: 0.00261559\n",
    "Iteration 1290\t Training error: 0.00261523\n",
    "Iteration 1291\t Training error: 0.00261487\n",
    "Iteration 1292\t Training error: 0.00261451\n",
    "Iteration 1293\t Training error: 0.00261415\n",
    "Iteration 1294\t Training error: 0.00261379\n",
    "Iteration 1295\t Training error: 0.00261342\n",
    "Iteration 1296\t Training error: 0.00261306\n",
    "Iteration 1297\t Training error: 0.0026127\n",
    "Iteration 1298\t Training error: 0.00261235\n",
    "Iteration 1299\t Training error: 0.00261199\n",
    "Iteration 1300\t Training error: 0.00261163\n",
    "Iteration 1301\t Training error: 0.00261127\n",
    "Iteration 1302\t Training error: 0.00261091\n",
    "Iteration 1303\t Training error: 0.00261056\n",
    "Iteration 1304\t Training error: 0.0026102\n",
    "Iteration 1305\t Training error: 0.00260984\n",
    "Iteration 1306\t Training error: 0.00260949\n",
    "Iteration 1307\t Training error: 0.00260913\n",
    "Iteration 1308\t Training error: 0.00260878\n",
    "Iteration 1309\t Training error: 0.00260842\n",
    "Iteration 1310\t Training error: 0.00260807\n",
    "Iteration 1311\t Training error: 0.00260772\n",
    "Iteration 1312\t Training error: 0.00260736\n",
    "Iteration 1313\t Training error: 0.00260701\n",
    "Iteration 1314\t Training error: 0.00260666\n",
    "Iteration 1315\t Training error: 0.00260631\n",
    "Iteration 1316\t Training error: 0.00260595\n",
    "Iteration 1317\t Training error: 0.0026056\n",
    "Iteration 1318\t Training error: 0.00260525\n",
    "Iteration 1319\t Training error: 0.0026049\n",
    "Iteration 1320\t Training error: 0.00260455\n",
    "Iteration 1321\t Training error: 0.0026042\n",
    "Iteration 1322\t Training error: 0.00260385\n",
    "Iteration 1323\t Training error: 0.00260351\n",
    "Iteration 1324\t Training error: 0.00260316\n",
    "Iteration 1325\t Training error: 0.00260281\n",
    "Iteration 1326\t Training error: 0.00260246\n",
    "Iteration 1327\t Training error: 0.00260212\n",
    "Iteration 1328\t Training error: 0.00260177\n",
    "Iteration 1329\t Training error: 0.00260142\n",
    "Iteration 1330\t Training error: 0.00260108\n",
    "Iteration 1331\t Training error: 0.00260073\n",
    "Iteration 1332\t Training error: 0.00260039\n",
    "Iteration 1333\t Training error: 0.00260004\n",
    "Iteration 1334\t Training error: 0.0025997\n",
    "Iteration 1335\t Training error: 0.00259935\n",
    "Iteration 1336\t Training error: 0.00259901\n",
    "Iteration 1337\t Training error: 0.00259867\n",
    "Iteration 1338\t Training error: 0.00259832\n",
    "Iteration 1339\t Training error: 0.00259798\n",
    "Iteration 1340\t Training error: 0.00259764\n",
    "Iteration 1341\t Training error: 0.0025973\n",
    "Iteration 1342\t Training error: 0.00259695\n",
    "Iteration 1343\t Training error: 0.00259661\n",
    "Iteration 1344\t Training error: 0.00259627\n",
    "Iteration 1345\t Training error: 0.00259593\n",
    "Iteration 1346\t Training error: 0.00259559\n",
    "Iteration 1347\t Training error: 0.00259525\n",
    "Iteration 1348\t Training error: 0.00259491\n",
    "Iteration 1349\t Training error: 0.00259457\n",
    "Iteration 1350\t Training error: 0.00259423\n",
    "Iteration 1351\t Training error: 0.0025939\n",
    "Iteration 1352\t Training error: 0.00259356\n",
    "Iteration 1353\t Training error: 0.00259322\n",
    "Iteration 1354\t Training error: 0.00259288\n",
    "Iteration 1355\t Training error: 0.00259255\n",
    "Iteration 1356\t Training error: 0.00259221\n",
    "Iteration 1357\t Training error: 0.00259187\n",
    "Iteration 1358\t Training error: 0.00259154\n",
    "Iteration 1359\t Training error: 0.0025912\n",
    "Iteration 1360\t Training error: 0.00259087\n",
    "Iteration 1361\t Training error: 0.00259053\n",
    "Iteration 1362\t Training error: 0.0025902\n",
    "Iteration 1363\t Training error: 0.00258986\n",
    "Iteration 1364\t Training error: 0.00258953\n",
    "Iteration 1365\t Training error: 0.00258919\n",
    "Iteration 1366\t Training error: 0.00258886\n",
    "Iteration 1367\t Training error: 0.00258853\n",
    "Iteration 1368\t Training error: 0.0025882\n",
    "Iteration 1369\t Training error: 0.00258786\n",
    "Iteration 1370\t Training error: 0.00258753\n",
    "Iteration 1371\t Training error: 0.0025872\n",
    "Iteration 1372\t Training error: 0.00258687\n",
    "Iteration 1373\t Training error: 0.00258654\n",
    "Iteration 1374\t Training error: 0.0025862\n",
    "Iteration 1375\t Training error: 0.00258587\n",
    "Iteration 1376\t Training error: 0.00258554\n",
    "Iteration 1377\t Training error: 0.00258521\n",
    "Iteration 1378\t Training error: 0.00258488\n",
    "Iteration 1379\t Training error: 0.00258455\n",
    "Iteration 1380\t Training error: 0.00258422\n",
    "Iteration 1381\t Training error: 0.0025839\n",
    "Iteration 1382\t Training error: 0.00258357\n",
    "Iteration 1383\t Training error: 0.00258324\n",
    "Iteration 1384\t Training error: 0.00258291\n",
    "Iteration 1385\t Training error: 0.00258258\n",
    "Iteration 1386\t Training error: 0.00258225\n",
    "Iteration 1387\t Training error: 0.00258193\n",
    "Iteration 1388\t Training error: 0.0025816\n",
    "Iteration 1389\t Training error: 0.00258127\n",
    "Iteration 1390\t Training error: 0.00258095\n",
    "Iteration 1391\t Training error: 0.00258062\n",
    "Iteration 1392\t Training error: 0.00258029\n",
    "Iteration 1393\t Training error: 0.00257997\n",
    "Iteration 1394\t Training error: 0.00257964\n",
    "Iteration 1395\t Training error: 0.00257932\n",
    "Iteration 1396\t Training error: 0.00257899\n",
    "Iteration 1397\t Training error: 0.00257867\n",
    "Iteration 1398\t Training error: 0.00257834\n",
    "Iteration 1399\t Training error: 0.00257802\n",
    "Iteration 1400\t Training error: 0.0025777\n",
    "Iteration 1401\t Training error: 0.00257737\n",
    "Iteration 1402\t Training error: 0.00257705\n",
    "Iteration 1403\t Training error: 0.00257673\n",
    "Iteration 1404\t Training error: 0.0025764\n",
    "Iteration 1405\t Training error: 0.00257608\n",
    "Iteration 1406\t Training error: 0.00257576\n",
    "Iteration 1407\t Training error: 0.00257544\n",
    "Iteration 1408\t Training error: 0.00257511\n",
    "Iteration 1409\t Training error: 0.00257479\n",
    "Iteration 1410\t Training error: 0.00257447\n",
    "Iteration 1411\t Training error: 0.00257415\n",
    "Iteration 1412\t Training error: 0.00257383\n",
    "Iteration 1413\t Training error: 0.00257351\n",
    "Iteration 1414\t Training error: 0.00257319\n",
    "Iteration 1415\t Training error: 0.00257287\n",
    "Iteration 1416\t Training error: 0.00257254\n",
    "Iteration 1417\t Training error: 0.00257222\n",
    "Iteration 1418\t Training error: 0.00257191\n",
    "Iteration 1419\t Training error: 0.00257159\n",
    "Iteration 1420\t Training error: 0.00257127\n",
    "Iteration 1421\t Training error: 0.00257095\n",
    "Iteration 1422\t Training error: 0.00257063\n",
    "Iteration 1423\t Training error: 0.00257031\n",
    "Iteration 1424\t Training error: 0.00256999\n",
    "Iteration 1425\t Training error: 0.00256967\n",
    "Iteration 1426\t Training error: 0.00256935\n",
    "Iteration 1427\t Training error: 0.00256904\n",
    "Iteration 1428\t Training error: 0.00256872\n",
    "Iteration 1429\t Training error: 0.0025684\n",
    "Iteration 1430\t Training error: 0.00256808\n",
    "Iteration 1431\t Training error: 0.00256777\n",
    "Iteration 1432\t Training error: 0.00256745\n",
    "Iteration 1433\t Training error: 0.00256713\n",
    "Iteration 1434\t Training error: 0.00256682\n",
    "Iteration 1435\t Training error: 0.0025665\n",
    "Iteration 1436\t Training error: 0.00256618\n",
    "Iteration 1437\t Training error: 0.00256587\n",
    "Iteration 1438\t Training error: 0.00256555\n",
    "Iteration 1439\t Training error: 0.00256524\n",
    "Iteration 1440\t Training error: 0.00256492\n",
    "Iteration 1441\t Training error: 0.0025646\n",
    "Iteration 1442\t Training error: 0.00256429\n",
    "Iteration 1443\t Training error: 0.00256397\n",
    "Iteration 1444\t Training error: 0.00256366\n",
    "Iteration 1445\t Training error: 0.00256335\n",
    "Iteration 1446\t Training error: 0.00256303\n",
    "Iteration 1447\t Training error: 0.00256272\n",
    "Iteration 1448\t Training error: 0.0025624\n",
    "Iteration 1449\t Training error: 0.00256209\n",
    "Iteration 1450\t Training error: 0.00256177\n",
    "Iteration 1451\t Training error: 0.00256146\n",
    "Iteration 1452\t Training error: 0.00256115\n",
    "Iteration 1453\t Training error: 0.00256083\n",
    "Iteration 1454\t Training error: 0.00256052\n",
    "Iteration 1455\t Training error: 0.00256021\n",
    "Iteration 1456\t Training error: 0.00255989\n",
    "Iteration 1457\t Training error: 0.00255958\n",
    "Iteration 1458\t Training error: 0.00255927\n",
    "Iteration 1459\t Training error: 0.00255896\n",
    "Iteration 1460\t Training error: 0.00255864\n",
    "Iteration 1461\t Training error: 0.00255833\n",
    "Iteration 1462\t Training error: 0.00255802\n",
    "Iteration 1463\t Training error: 0.00255771\n",
    "Iteration 1464\t Training error: 0.0025574\n",
    "Iteration 1465\t Training error: 0.00255708\n",
    "Iteration 1466\t Training error: 0.00255677\n",
    "Iteration 1467\t Training error: 0.00255646\n",
    "Iteration 1468\t Training error: 0.00255615\n",
    "Iteration 1469\t Training error: 0.00255584\n",
    "Iteration 1470\t Training error: 0.00255553\n",
    "Iteration 1471\t Training error: 0.00255522\n",
    "Iteration 1472\t Training error: 0.00255491\n",
    "Iteration 1473\t Training error: 0.0025546\n",
    "Iteration 1474\t Training error: 0.00255428\n",
    "Iteration 1475\t Training error: 0.00255397\n",
    "Iteration 1476\t Training error: 0.00255366\n",
    "Iteration 1477\t Training error: 0.00255335\n",
    "Iteration 1478\t Training error: 0.00255304\n",
    "Iteration 1479\t Training error: 0.00255273\n",
    "Iteration 1480\t Training error: 0.00255242\n",
    "Iteration 1481\t Training error: 0.00255211\n",
    "Iteration 1482\t Training error: 0.0025518\n",
    "Iteration 1483\t Training error: 0.00255149\n",
    "Iteration 1484\t Training error: 0.00255119\n",
    "Iteration 1485\t Training error: 0.00255088\n",
    "Iteration 1486\t Training error: 0.00255057\n",
    "Iteration 1487\t Training error: 0.00255026\n",
    "Iteration 1488\t Training error: 0.00254995\n",
    "Iteration 1489\t Training error: 0.00254964\n",
    "Iteration 1490\t Training error: 0.00254933\n",
    "Iteration 1491\t Training error: 0.00254902\n",
    "Iteration 1492\t Training error: 0.00254871\n",
    "Iteration 1493\t Training error: 0.0025484\n",
    "Iteration 1494\t Training error: 0.00254809\n",
    "Iteration 1495\t Training error: 0.00254779\n",
    "Iteration 1496\t Training error: 0.00254748\n",
    "Iteration 1497\t Training error: 0.00254717\n",
    "Iteration 1498\t Training error: 0.00254686\n",
    "Iteration 1499\t Training error: 0.00254655\n",
    "Iteration 1500\t Training error: 0.00254624\n",
    "Iteration 1501\t Training error: 0.00254594\n",
    "Iteration 1502\t Training error: 0.00254563\n",
    "Iteration 1503\t Training error: 0.00254532\n",
    "Iteration 1504\t Training error: 0.00254501\n",
    "Iteration 1505\t Training error: 0.0025447\n",
    "Iteration 1506\t Training error: 0.0025444\n",
    "Iteration 1507\t Training error: 0.00254409\n",
    "Iteration 1508\t Training error: 0.00254378\n",
    "Iteration 1509\t Training error: 0.00254347\n",
    "Iteration 1510\t Training error: 0.00254317\n",
    "Iteration 1511\t Training error: 0.00254286\n",
    "Iteration 1512\t Training error: 0.00254255\n",
    "Iteration 1513\t Training error: 0.00254224\n",
    "Iteration 1514\t Training error: 0.00254193\n",
    "Iteration 1515\t Training error: 0.00254163\n",
    "Iteration 1516\t Training error: 0.00254132\n",
    "Iteration 1517\t Training error: 0.00254101\n",
    "Iteration 1518\t Training error: 0.00254071\n",
    "Iteration 1519\t Training error: 0.0025404\n",
    "Iteration 1520\t Training error: 0.00254009\n",
    "Iteration 1521\t Training error: 0.00253978\n",
    "Iteration 1522\t Training error: 0.00253948\n",
    "Iteration 1523\t Training error: 0.00253917\n",
    "Iteration 1524\t Training error: 0.00253886\n",
    "Iteration 1525\t Training error: 0.00253855\n",
    "Iteration 1526\t Training error: 0.00253825\n",
    "Iteration 1527\t Training error: 0.00253794\n",
    "Iteration 1528\t Training error: 0.00253763\n",
    "Iteration 1529\t Training error: 0.00253733\n",
    "Iteration 1530\t Training error: 0.00253702\n",
    "Iteration 1531\t Training error: 0.00253671\n",
    "Iteration 1532\t Training error: 0.0025364\n",
    "Iteration 1533\t Training error: 0.0025361\n",
    "Iteration 1534\t Training error: 0.00253579\n",
    "Iteration 1535\t Training error: 0.00253548\n",
    "Iteration 1536\t Training error: 0.00253518\n",
    "Iteration 1537\t Training error: 0.00253487\n",
    "Iteration 1538\t Training error: 0.00253456\n",
    "Iteration 1539\t Training error: 0.00253425\n",
    "Iteration 1540\t Training error: 0.00253395\n",
    "Iteration 1541\t Training error: 0.00253364\n",
    "Iteration 1542\t Training error: 0.00253333\n",
    "Iteration 1543\t Training error: 0.00253303\n",
    "Iteration 1544\t Training error: 0.00253272\n",
    "Iteration 1545\t Training error: 0.00253241\n",
    "Iteration 1546\t Training error: 0.0025321\n",
    "Iteration 1547\t Training error: 0.0025318\n",
    "Iteration 1548\t Training error: 0.00253149\n",
    "Iteration 1549\t Training error: 0.00253118\n",
    "Iteration 1550\t Training error: 0.00253087\n",
    "Iteration 1551\t Training error: 0.00253057\n",
    "Iteration 1552\t Training error: 0.00253026\n",
    "Iteration 1553\t Training error: 0.00252995\n",
    "Iteration 1554\t Training error: 0.00252964\n",
    "Iteration 1555\t Training error: 0.00252934\n",
    "Iteration 1556\t Training error: 0.00252903\n",
    "Iteration 1557\t Training error: 0.00252872\n",
    "Iteration 1558\t Training error: 0.00252841\n",
    "Iteration 1559\t Training error: 0.0025281\n",
    "Iteration 1560\t Training error: 0.0025278\n",
    "Iteration 1561\t Training error: 0.00252749\n",
    "Iteration 1562\t Training error: 0.00252718\n",
    "Iteration 1563\t Training error: 0.00252687\n",
    "Iteration 1564\t Training error: 0.00252656\n",
    "Iteration 1565\t Training error: 0.00252626\n",
    "Iteration 1566\t Training error: 0.00252595\n",
    "Iteration 1567\t Training error: 0.00252564\n",
    "Iteration 1568\t Training error: 0.00252533\n",
    "Iteration 1569\t Training error: 0.00252502\n",
    "Iteration 1570\t Training error: 0.00252471\n",
    "Iteration 1571\t Training error: 0.0025244\n",
    "Iteration 1572\t Training error: 0.0025241\n",
    "Iteration 1573\t Training error: 0.00252379\n",
    "Iteration 1574\t Training error: 0.00252348\n",
    "Iteration 1575\t Training error: 0.00252317\n",
    "Iteration 1576\t Training error: 0.00252286\n",
    "Iteration 1577\t Training error: 0.00252255\n",
    "Iteration 1578\t Training error: 0.00252224\n",
    "Iteration 1579\t Training error: 0.00252193\n",
    "Iteration 1580\t Training error: 0.00252162\n",
    "Iteration 1581\t Training error: 0.00252131\n",
    "Iteration 1582\t Training error: 0.002521\n",
    "Iteration 1583\t Training error: 0.00252069\n",
    "Iteration 1584\t Training error: 0.00252038\n",
    "Iteration 1585\t Training error: 0.00252007\n",
    "Iteration 1586\t Training error: 0.00251976\n",
    "Iteration 1587\t Training error: 0.00251945\n",
    "Iteration 1588\t Training error: 0.00251914\n",
    "Iteration 1589\t Training error: 0.00251883\n",
    "Iteration 1590\t Training error: 0.00251852\n",
    "Iteration 1591\t Training error: 0.00251821\n",
    "Iteration 1592\t Training error: 0.0025179\n",
    "Iteration 1593\t Training error: 0.00251759\n",
    "Iteration 1594\t Training error: 0.00251727\n",
    "Iteration 1595\t Training error: 0.00251696\n",
    "Iteration 1596\t Training error: 0.00251665\n",
    "Iteration 1597\t Training error: 0.00251634\n",
    "Iteration 1598\t Training error: 0.00251603\n",
    "Iteration 1599\t Training error: 0.00251572\n",
    "Iteration 1600\t Training error: 0.0025154\n",
    "Iteration 1601\t Training error: 0.00251509\n",
    "Iteration 1602\t Training error: 0.00251478\n",
    "Iteration 1603\t Training error: 0.00251447\n",
    "Iteration 1604\t Training error: 0.00251415\n",
    "Iteration 1605\t Training error: 0.00251384\n",
    "Iteration 1606\t Training error: 0.00251353\n",
    "Iteration 1607\t Training error: 0.00251321\n",
    "Iteration 1608\t Training error: 0.0025129\n",
    "Iteration 1609\t Training error: 0.00251259\n",
    "Iteration 1610\t Training error: 0.00251227\n",
    "Iteration 1611\t Training error: 0.00251196\n",
    "Iteration 1612\t Training error: 0.00251164\n",
    "Iteration 1613\t Training error: 0.00251133\n",
    "Iteration 1614\t Training error: 0.00251102\n",
    "Iteration 1615\t Training error: 0.0025107\n",
    "Iteration 1616\t Training error: 0.00251039\n",
    "Iteration 1617\t Training error: 0.00251007\n",
    "Iteration 1618\t Training error: 0.00250975\n",
    "Iteration 1619\t Training error: 0.00250944\n",
    "Iteration 1620\t Training error: 0.00250912\n",
    "Iteration 1621\t Training error: 0.00250881\n",
    "Iteration 1622\t Training error: 0.00250849\n",
    "Iteration 1623\t Training error: 0.00250818\n",
    "Iteration 1624\t Training error: 0.00250786\n",
    "Iteration 1625\t Training error: 0.00250754\n",
    "Iteration 1626\t Training error: 0.00250722\n",
    "Iteration 1627\t Training error: 0.00250691\n",
    "Iteration 1628\t Training error: 0.00250659\n",
    "Iteration 1629\t Training error: 0.00250627\n",
    "Iteration 1630\t Training error: 0.00250595\n",
    "Iteration 1631\t Training error: 0.00250564\n",
    "Iteration 1632\t Training error: 0.00250532\n",
    "Iteration 1633\t Training error: 0.002505\n",
    "Iteration 1634\t Training error: 0.00250468\n",
    "Iteration 1635\t Training error: 0.00250436\n",
    "Iteration 1636\t Training error: 0.00250404\n",
    "Iteration 1637\t Training error: 0.00250372\n",
    "Iteration 1638\t Training error: 0.0025034\n",
    "Iteration 1639\t Training error: 0.00250308\n",
    "Iteration 1640\t Training error: 0.00250276\n",
    "Iteration 1641\t Training error: 0.00250244\n",
    "Iteration 1642\t Training error: 0.00250212\n",
    "Iteration 1643\t Training error: 0.0025018\n",
    "Iteration 1644\t Training error: 0.00250148\n",
    "Iteration 1645\t Training error: 0.00250116\n",
    "Iteration 1646\t Training error: 0.00250084\n",
    "Iteration 1647\t Training error: 0.00250051\n",
    "Iteration 1648\t Training error: 0.00250019\n",
    "Iteration 1649\t Training error: 0.00249987\n",
    "Iteration 1650\t Training error: 0.00249955\n",
    "Iteration 1651\t Training error: 0.00249922\n",
    "Iteration 1652\t Training error: 0.0024989\n",
    "Iteration 1653\t Training error: 0.00249858\n",
    "Iteration 1654\t Training error: 0.00249825\n",
    "Iteration 1655\t Training error: 0.00249793\n",
    "Iteration 1656\t Training error: 0.0024976\n",
    "Iteration 1657\t Training error: 0.00249728\n",
    "Iteration 1658\t Training error: 0.00249695\n",
    "Iteration 1659\t Training error: 0.00249663\n",
    "Iteration 1660\t Training error: 0.0024963\n",
    "Iteration 1661\t Training error: 0.00249597\n",
    "Iteration 1662\t Training error: 0.00249565\n",
    "Iteration 1663\t Training error: 0.00249532\n",
    "Iteration 1664\t Training error: 0.00249499\n",
    "Iteration 1665\t Training error: 0.00249467\n",
    "Iteration 1666\t Training error: 0.00249434\n",
    "Iteration 1667\t Training error: 0.00249401\n",
    "Iteration 1668\t Training error: 0.00249368\n",
    "Iteration 1669\t Training error: 0.00249336\n",
    "Iteration 1670\t Training error: 0.00249303\n",
    "Iteration 1671\t Training error: 0.0024927\n",
    "Iteration 1672\t Training error: 0.00249237\n",
    "Iteration 1673\t Training error: 0.00249204\n",
    "Iteration 1674\t Training error: 0.00249171\n",
    "Iteration 1675\t Training error: 0.00249138\n",
    "Iteration 1676\t Training error: 0.00249105\n",
    "Iteration 1677\t Training error: 0.00249072\n",
    "Iteration 1678\t Training error: 0.00249038\n",
    "Iteration 1679\t Training error: 0.00249005\n",
    "Iteration 1680\t Training error: 0.00248972\n",
    "Iteration 1681\t Training error: 0.00248939\n",
    "Iteration 1682\t Training error: 0.00248905\n",
    "Iteration 1683\t Training error: 0.00248872\n",
    "Iteration 1684\t Training error: 0.00248839\n",
    "Iteration 1685\t Training error: 0.00248805\n",
    "Iteration 1686\t Training error: 0.00248772\n",
    "Iteration 1687\t Training error: 0.00248739\n",
    "Iteration 1688\t Training error: 0.00248705\n",
    "Iteration 1689\t Training error: 0.00248672\n",
    "Iteration 1690\t Training error: 0.00248638\n",
    "Iteration 1691\t Training error: 0.00248604\n",
    "Iteration 1692\t Training error: 0.00248571\n",
    "Iteration 1693\t Training error: 0.00248537\n",
    "Iteration 1694\t Training error: 0.00248503\n",
    "Iteration 1695\t Training error: 0.0024847\n",
    "Iteration 1696\t Training error: 0.00248436\n",
    "Iteration 1697\t Training error: 0.00248402\n",
    "Iteration 1698\t Training error: 0.00248368\n",
    "Iteration 1699\t Training error: 0.00248334\n",
    "Iteration 1700\t Training error: 0.002483\n",
    "Iteration 1701\t Training error: 0.00248266\n",
    "Iteration 1702\t Training error: 0.00248232\n",
    "Iteration 1703\t Training error: 0.00248198\n",
    "Iteration 1704\t Training error: 0.00248164\n",
    "Iteration 1705\t Training error: 0.0024813\n",
    "Iteration 1706\t Training error: 0.00248096\n",
    "Iteration 1707\t Training error: 0.00248062\n",
    "Iteration 1708\t Training error: 0.00248027\n",
    "Iteration 1709\t Training error: 0.00247993\n",
    "Iteration 1710\t Training error: 0.00247959\n",
    "Iteration 1711\t Training error: 0.00247924\n",
    "Iteration 1712\t Training error: 0.0024789\n",
    "Iteration 1713\t Training error: 0.00247856\n",
    "Iteration 1714\t Training error: 0.00247821\n",
    "Iteration 1715\t Training error: 0.00247787\n",
    "Iteration 1716\t Training error: 0.00247752\n",
    "Iteration 1717\t Training error: 0.00247717\n",
    "Iteration 1718\t Training error: 0.00247683\n",
    "Iteration 1719\t Training error: 0.00247648\n",
    "Iteration 1720\t Training error: 0.00247613\n",
    "Iteration 1721\t Training error: 0.00247578\n",
    "Iteration 1722\t Training error: 0.00247544\n",
    "Iteration 1723\t Training error: 0.00247509\n",
    "Iteration 1724\t Training error: 0.00247474\n",
    "Iteration 1725\t Training error: 0.00247439\n",
    "Iteration 1726\t Training error: 0.00247404\n",
    "Iteration 1727\t Training error: 0.00247369\n",
    "Iteration 1728\t Training error: 0.00247334\n",
    "Iteration 1729\t Training error: 0.00247299\n",
    "Iteration 1730\t Training error: 0.00247264\n",
    "Iteration 1731\t Training error: 0.00247228\n",
    "Iteration 1732\t Training error: 0.00247193\n",
    "Iteration 1733\t Training error: 0.00247158\n",
    "Iteration 1734\t Training error: 0.00247123\n",
    "Iteration 1735\t Training error: 0.00247087\n",
    "Iteration 1736\t Training error: 0.00247052\n",
    "Iteration 1737\t Training error: 0.00247016\n",
    "Iteration 1738\t Training error: 0.00246981\n",
    "Iteration 1739\t Training error: 0.00246945\n",
    "Iteration 1740\t Training error: 0.0024691\n",
    "Iteration 1741\t Training error: 0.00246874\n",
    "Iteration 1742\t Training error: 0.00246838\n",
    "Iteration 1743\t Training error: 0.00246803\n",
    "Iteration 1744\t Training error: 0.00246767\n",
    "Iteration 1745\t Training error: 0.00246731\n",
    "Iteration 1746\t Training error: 0.00246695\n",
    "Iteration 1747\t Training error: 0.00246659\n",
    "Iteration 1748\t Training error: 0.00246623\n",
    "Iteration 1749\t Training error: 0.00246587\n",
    "Iteration 1750\t Training error: 0.00246551\n",
    "Iteration 1751\t Training error: 0.00246515\n",
    "Iteration 1752\t Training error: 0.00246479\n",
    "Iteration 1753\t Training error: 0.00246443\n",
    "Iteration 1754\t Training error: 0.00246407\n",
    "Iteration 1755\t Training error: 0.0024637\n",
    "Iteration 1756\t Training error: 0.00246334\n",
    "Iteration 1757\t Training error: 0.00246298\n",
    "Iteration 1758\t Training error: 0.00246261\n",
    "Iteration 1759\t Training error: 0.00246225\n",
    "Iteration 1760\t Training error: 0.00246188\n",
    "Iteration 1761\t Training error: 0.00246152\n",
    "Iteration 1762\t Training error: 0.00246115\n",
    "Iteration 1763\t Training error: 0.00246078\n",
    "Iteration 1764\t Training error: 0.00246042\n",
    "Iteration 1765\t Training error: 0.00246005\n",
    "Iteration 1766\t Training error: 0.00245968\n",
    "Iteration 1767\t Training error: 0.00245931\n",
    "Iteration 1768\t Training error: 0.00245895\n",
    "Iteration 1769\t Training error: 0.00245858\n",
    "Iteration 1770\t Training error: 0.00245821\n",
    "Iteration 1771\t Training error: 0.00245784\n",
    "Iteration 1772\t Training error: 0.00245747\n",
    "Iteration 1773\t Training error: 0.00245709\n",
    "Iteration 1774\t Training error: 0.00245672\n",
    "Iteration 1775\t Training error: 0.00245635\n",
    "Iteration 1776\t Training error: 0.00245598\n",
    "Iteration 1777\t Training error: 0.00245561\n",
    "Iteration 1778\t Training error: 0.00245523\n",
    "Iteration 1779\t Training error: 0.00245486\n",
    "Iteration 1780\t Training error: 0.00245448\n",
    "Iteration 1781\t Training error: 0.00245411\n",
    "Iteration 1782\t Training error: 0.00245373\n",
    "Iteration 1783\t Training error: 0.00245336\n",
    "Iteration 1784\t Training error: 0.00245298\n",
    "Iteration 1785\t Training error: 0.0024526\n",
    "Iteration 1786\t Training error: 0.00245223\n",
    "Iteration 1787\t Training error: 0.00245185\n",
    "Iteration 1788\t Training error: 0.00245147\n",
    "Iteration 1789\t Training error: 0.00245109\n",
    "Iteration 1790\t Training error: 0.00245071\n",
    "Iteration 1791\t Training error: 0.00245033\n",
    "Iteration 1792\t Training error: 0.00244995\n",
    "Iteration 1793\t Training error: 0.00244957\n",
    "Iteration 1794\t Training error: 0.00244919\n",
    "Iteration 1795\t Training error: 0.00244881\n",
    "Iteration 1796\t Training error: 0.00244843\n",
    "Iteration 1797\t Training error: 0.00244805\n",
    "Iteration 1798\t Training error: 0.00244766\n",
    "Iteration 1799\t Training error: 0.00244728\n",
    "Iteration 1800\t Training error: 0.0024469\n",
    "Iteration 1801\t Training error: 0.00244651\n",
    "Iteration 1802\t Training error: 0.00244613\n",
    "Iteration 1803\t Training error: 0.00244574\n",
    "Iteration 1804\t Training error: 0.00244536\n",
    "Iteration 1805\t Training error: 0.00244497\n",
    "Iteration 1806\t Training error: 0.00244458\n",
    "Iteration 1807\t Training error: 0.00244419\n",
    "Iteration 1808\t Training error: 0.00244381\n",
    "Iteration 1809\t Training error: 0.00244342\n",
    "Iteration 1810\t Training error: 0.00244303\n",
    "Iteration 1811\t Training error: 0.00244264\n",
    "Iteration 1812\t Training error: 0.00244225\n",
    "Iteration 1813\t Training error: 0.00244186\n",
    "Iteration 1814\t Training error: 0.00244147\n",
    "Iteration 1815\t Training error: 0.00244108\n",
    "Iteration 1816\t Training error: 0.00244069\n",
    "Iteration 1817\t Training error: 0.0024403\n",
    "Iteration 1818\t Training error: 0.0024399\n",
    "Iteration 1819\t Training error: 0.00243951\n",
    "Iteration 1820\t Training error: 0.00243912\n",
    "Iteration 1821\t Training error: 0.00243872\n",
    "Iteration 1822\t Training error: 0.00243833\n",
    "Iteration 1823\t Training error: 0.00243794\n",
    "Iteration 1824\t Training error: 0.00243754\n",
    "Iteration 1825\t Training error: 0.00243714\n",
    "Iteration 1826\t Training error: 0.00243675\n",
    "Iteration 1827\t Training error: 0.00243635\n",
    "Iteration 1828\t Training error: 0.00243596\n",
    "Iteration 1829\t Training error: 0.00243556\n",
    "Iteration 1830\t Training error: 0.00243516\n",
    "Iteration 1831\t Training error: 0.00243476\n",
    "Iteration 1832\t Training error: 0.00243436\n",
    "Iteration 1833\t Training error: 0.00243396\n",
    "Iteration 1834\t Training error: 0.00243356\n",
    "Iteration 1835\t Training error: 0.00243316\n",
    "Iteration 1836\t Training error: 0.00243276\n",
    "Iteration 1837\t Training error: 0.00243236\n",
    "Iteration 1838\t Training error: 0.00243196\n",
    "Iteration 1839\t Training error: 0.00243156\n",
    "Iteration 1840\t Training error: 0.00243116\n",
    "Iteration 1841\t Training error: 0.00243075\n",
    "Iteration 1842\t Training error: 0.00243035\n",
    "Iteration 1843\t Training error: 0.00242995\n",
    "Iteration 1844\t Training error: 0.00242954\n",
    "Iteration 1845\t Training error: 0.00242914\n",
    "Iteration 1846\t Training error: 0.00242873\n",
    "Iteration 1847\t Training error: 0.00242833\n",
    "Iteration 1848\t Training error: 0.00242792\n",
    "Iteration 1849\t Training error: 0.00242751\n",
    "Iteration 1850\t Training error: 0.00242711\n",
    "Iteration 1851\t Training error: 0.0024267\n",
    "Iteration 1852\t Training error: 0.00242629\n",
    "Iteration 1853\t Training error: 0.00242588\n",
    "Iteration 1854\t Training error: 0.00242548\n",
    "Iteration 1855\t Training error: 0.00242507\n",
    "Iteration 1856\t Training error: 0.00242466\n",
    "Iteration 1857\t Training error: 0.00242425\n",
    "Iteration 1858\t Training error: 0.00242384\n",
    "Iteration 1859\t Training error: 0.00242343\n",
    "Iteration 1860\t Training error: 0.00242302\n",
    "Iteration 1861\t Training error: 0.0024226\n",
    "Iteration 1862\t Training error: 0.00242219\n",
    "Iteration 1863\t Training error: 0.00242178\n",
    "Iteration 1864\t Training error: 0.00242137\n",
    "Iteration 1865\t Training error: 0.00242095\n",
    "Iteration 1866\t Training error: 0.00242054\n",
    "Iteration 1867\t Training error: 0.00242013\n",
    "Iteration 1868\t Training error: 0.00241971\n",
    "Iteration 1869\t Training error: 0.0024193\n",
    "Iteration 1870\t Training error: 0.00241888\n",
    "Iteration 1871\t Training error: 0.00241847\n",
    "Iteration 1872\t Training error: 0.00241805\n",
    "Iteration 1873\t Training error: 0.00241763\n",
    "Iteration 1874\t Training error: 0.00241722\n",
    "Iteration 1875\t Training error: 0.0024168\n",
    "Iteration 1876\t Training error: 0.00241638\n",
    "Iteration 1877\t Training error: 0.00241597\n",
    "Iteration 1878\t Training error: 0.00241555\n",
    "Iteration 1879\t Training error: 0.00241513\n",
    "Iteration 1880\t Training error: 0.00241471\n",
    "Iteration 1881\t Training error: 0.00241429\n",
    "Iteration 1882\t Training error: 0.00241387\n",
    "Iteration 1883\t Training error: 0.00241345\n",
    "Iteration 1884\t Training error: 0.00241303\n",
    "Iteration 1885\t Training error: 0.00241261\n",
    "Iteration 1886\t Training error: 0.00241219\n",
    "Iteration 1887\t Training error: 0.00241177\n",
    "Iteration 1888\t Training error: 0.00241134\n",
    "Iteration 1889\t Training error: 0.00241092\n",
    "Iteration 1890\t Training error: 0.0024105\n",
    "Iteration 1891\t Training error: 0.00241008\n",
    "Iteration 1892\t Training error: 0.00240965\n",
    "Iteration 1893\t Training error: 0.00240923\n",
    "Iteration 1894\t Training error: 0.0024088\n",
    "Iteration 1895\t Training error: 0.00240838\n",
    "Iteration 1896\t Training error: 0.00240795\n",
    "Iteration 1897\t Training error: 0.00240753\n",
    "Iteration 1898\t Training error: 0.0024071\n",
    "Iteration 1899\t Training error: 0.00240668\n",
    "Iteration 1900\t Training error: 0.00240625\n",
    "Iteration 1901\t Training error: 0.00240583\n",
    "Iteration 1902\t Training error: 0.0024054\n",
    "Iteration 1903\t Training error: 0.00240497\n",
    "Iteration 1904\t Training error: 0.00240454\n",
    "Iteration 1905\t Training error: 0.00240412\n",
    "Iteration 1906\t Training error: 0.00240369\n",
    "Iteration 1907\t Training error: 0.00240326\n",
    "Iteration 1908\t Training error: 0.00240283\n",
    "Iteration 1909\t Training error: 0.0024024\n",
    "Iteration 1910\t Training error: 0.00240197\n",
    "Iteration 1911\t Training error: 0.00240154\n",
    "Iteration 1912\t Training error: 0.00240111\n",
    "Iteration 1913\t Training error: 0.00240068\n",
    "Iteration 1914\t Training error: 0.00240025\n",
    "Iteration 1915\t Training error: 0.00239982\n",
    "Iteration 1916\t Training error: 0.00239939\n",
    "Iteration 1917\t Training error: 0.00239896\n",
    "Iteration 1918\t Training error: 0.00239853\n",
    "Iteration 1919\t Training error: 0.00239809\n",
    "Iteration 1920\t Training error: 0.00239766\n",
    "Iteration 1921\t Training error: 0.00239723\n",
    "Iteration 1922\t Training error: 0.0023968\n",
    "Iteration 1923\t Training error: 0.00239636\n",
    "Iteration 1924\t Training error: 0.00239593\n",
    "Iteration 1925\t Training error: 0.0023955\n",
    "Iteration 1926\t Training error: 0.00239506\n",
    "Iteration 1927\t Training error: 0.00239463\n",
    "Iteration 1928\t Training error: 0.00239419\n",
    "Iteration 1929\t Training error: 0.00239376\n",
    "Iteration 1930\t Training error: 0.00239332\n",
    "Iteration 1931\t Training error: 0.00239289\n",
    "Iteration 1932\t Training error: 0.00239245\n",
    "Iteration 1933\t Training error: 0.00239202\n",
    "Iteration 1934\t Training error: 0.00239158\n",
    "Iteration 1935\t Training error: 0.00239115\n",
    "Iteration 1936\t Training error: 0.00239071\n",
    "Iteration 1937\t Training error: 0.00239027\n",
    "Iteration 1938\t Training error: 0.00238984\n",
    "Iteration 1939\t Training error: 0.0023894\n",
    "Iteration 1940\t Training error: 0.00238896\n",
    "Iteration 1941\t Training error: 0.00238852\n",
    "Iteration 1942\t Training error: 0.00238809\n",
    "Iteration 1943\t Training error: 0.00238765\n",
    "Iteration 1944\t Training error: 0.00238721\n",
    "Iteration 1945\t Training error: 0.00238677\n",
    "Iteration 1946\t Training error: 0.00238633\n",
    "Iteration 1947\t Training error: 0.00238589\n",
    "Iteration 1948\t Training error: 0.00238545\n",
    "Iteration 1949\t Training error: 0.00238501\n",
    "Iteration 1950\t Training error: 0.00238458\n",
    "Iteration 1951\t Training error: 0.00238414\n",
    "Iteration 1952\t Training error: 0.0023837\n",
    "Iteration 1953\t Training error: 0.00238326\n",
    "Iteration 1954\t Training error: 0.00238282\n",
    "Iteration 1955\t Training error: 0.00238238\n",
    "Iteration 1956\t Training error: 0.00238193\n",
    "Iteration 1957\t Training error: 0.00238149\n",
    "Iteration 1958\t Training error: 0.00238105\n",
    "Iteration 1959\t Training error: 0.00238061\n",
    "Iteration 1960\t Training error: 0.00238017\n",
    "Iteration 1961\t Training error: 0.00237973\n",
    "Iteration 1962\t Training error: 0.00237929\n",
    "Iteration 1963\t Training error: 0.00237885\n",
    "Iteration 1964\t Training error: 0.0023784\n",
    "Iteration 1965\t Training error: 0.00237796\n",
    "Iteration 1966\t Training error: 0.00237752\n",
    "Iteration 1967\t Training error: 0.00237708\n",
    "Iteration 1968\t Training error: 0.00237664\n",
    "Iteration 1969\t Training error: 0.00237619\n",
    "Iteration 1970\t Training error: 0.00237575\n",
    "Iteration 1971\t Training error: 0.00237531\n",
    "Iteration 1972\t Training error: 0.00237486\n",
    "Iteration 1973\t Training error: 0.00237442\n",
    "Iteration 1974\t Training error: 0.00237398\n",
    "Iteration 1975\t Training error: 0.00237353\n",
    "Iteration 1976\t Training error: 0.00237309\n",
    "Iteration 1977\t Training error: 0.00237265\n",
    "Iteration 1978\t Training error: 0.0023722\n",
    "Iteration 1979\t Training error: 0.00237176\n",
    "Iteration 1980\t Training error: 0.00237132\n",
    "Iteration 1981\t Training error: 0.00237087\n",
    "Iteration 1982\t Training error: 0.00237043\n",
    "Iteration 1983\t Training error: 0.00236998\n",
    "Iteration 1984\t Training error: 0.00236954\n",
    "Iteration 1985\t Training error: 0.0023691\n",
    "Iteration 1986\t Training error: 0.00236865\n",
    "Iteration 1987\t Training error: 0.00236821\n",
    "Iteration 1988\t Training error: 0.00236776\n",
    "Iteration 1989\t Training error: 0.00236732\n",
    "Iteration 1990\t Training error: 0.00236687\n",
    "Iteration 1991\t Training error: 0.00236643\n",
    "Iteration 1992\t Training error: 0.00236598\n",
    "Iteration 1993\t Training error: 0.00236554\n",
    "Iteration 1994\t Training error: 0.00236509\n",
    "Iteration 1995\t Training error: 0.00236465\n",
    "Iteration 1996\t Training error: 0.0023642\n",
    "Iteration 1997\t Training error: 0.00236376\n",
    "Iteration 1998\t Training error: 0.00236331\n",
    "Iteration 1999\t Training error: 0.00236287\n",
    "Iteration 2000\t Training error: 0.00236242\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos expresiones regulares para extraer las iteraciones y los errores de entrenamiento\n",
    "patron = r\"Iteration (\\d+)\\s+Training error: ([\\d.]+)\"\n",
    "resultados = re.findall(patron, cadena)\n",
    "\n",
    "# Extraemos los nÃºmeros de iteraciÃ³n y los errores\n",
    "iteraciones = [int(resultado[0]) for resultado in resultados]\n",
    "errores = [float(resultado[1]) for resultado in resultados]\n",
    "\n",
    "# Creamos la grÃ¡fica\n",
    "plt.plot(iteraciones, errores, linestyle='-', marker='')  # Sin puntos, solo la lÃ­nea\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training error')\n",
    "plt.title('Training error over iterations')\n",
    "plt.grid(True)\n",
    "\n",
    "# Mostramos la grÃ¡fica\n",
    "plt.savefig(os.path.join(output_dir, f't_e_mpg.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./bin/la1', '-t', './dat/train_mpg.dat', '-s', '-T', './dat/test_mpg.dat', '-e', '0.1', '-m', '0.5', '-l', '4', '-h', '11', '-i', '2000']\n"
     ]
    }
   ],
   "source": [
    "# Executes and Writes the output of the execution of the best results on a txt\n",
    "result = subprocess.run([\"./bin/la1\", \"-t\", train_files[0],\"-s\", \"-T\", test_files[0], \"-e\", str(best_config_test[\"eta\"]), \"-m\", str(best_config_test[\"mu\"]), \"-l\", str(best_config_test[\"layers\"]), \"-h\", str(best_config_test[\"neurons\"]), \"-i\", str(best_config_test[\"iterations\"], \"-w\", \"weights.txt\")],           capture_output=True, text=True        )\n",
    "print([\"./bin/la1\", \"-t\",train_files[0],\"-s\", \"-T\", test_files[0], \"-e\", str(best_config_test[\"eta\"]), \"-m\", str(best_config_test[\"mu\"]), \"-l\", str(best_config_test[\"layers\"]), \"-h\", str(best_config_test[\"neurons\"]), \"-i\", str(best_config_test[\"iterations\"])])\n",
    "with open(os.path.join(output_dir, f'best_results.txt'), 'w') as f:\n",
    "    f.write(result.stdout)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'puntos_rosas = \"\"\"0.0909091 -- 0.184661 \\n0.0909091 -- 0.176442 \\n0.272727 -- 0.153274 \\n0.0909091 -- 0.154304 \\n0.272727 -- 0.184137 \\n0 -- 0.164192 \\n0.363636 -- 0.169845 \\n0 -- 0.15867 \\n0.272727 -- 0.172583 \\n0.0909091 -- 0.173976 \\n0.181818 -- 0.164771 \\n0 -- 0.0928139 \\n0.636364 -- 0.187773 \\n0 -- 0.150008 \\n0.272727 -- 0.171904 \\n0 -- 0.166369 \\n0.363636 -- 0.171416 \\n0.0909091 -- 0.154811 \\n0.0909091 -- 0.169766 \\n0.272727 -- 0.182663 \\n0 -- 0.161647 \\n0 -- 0.160613 \\n0.636364 -- 0.154855 \\n0.363636 -- 0.161513 \\n0.454545 -- 0.144694 \\n0.272727 -- 0.14977 \\n0.0909091 -- 0.160532 \\n0.0909091 -- 0.201691 \\n0.272727 -- 0.156351 \\n0.0909091 -- 0.13097 \\n0 -- 0.180985 \\n0.181818 -- 0.169247 \\n0.363636 -- 0.173747 \\n0.181818 -- 0.157044 \\n0.181818 -- 0.0986682 \\n0 -- 0.132816 \\n0 -- 0.171388 \\n0 -- 0.163375 \\n0.272727 -- 0.164469 \\n0 -- 0.166233 \\n0.0909091 -- 0.157515 \\n0.0909091 -- 0.149029 \\n0.272727 -- 0.158062 \\n0.363636 -- 0.161787 \\n0.272727 -- 0.169089 \\n0.0909091 -- 0.153206 \\n0.0909091 -- 0.164165 \\n0.0909091 -- 0.160652 \\n0.0909091 -- 0.159343 \\n0.0909091 -- 0.171151 \\n0.0909091 -- 0.140034 \\n0.818182 -- 0.376479 \\n0.545455 -- 0.169724 \\n0 -- 0.165767 \\n0.272727 -- 0.189385 \\n0.272727 -- 0.162908 \\n0 -- 0.150688 \\n0.0909091 -- 0.187137 \\n0.363636 -- 0.164585 \\n0.0909091 -- 0.160835 \\n0.272727 -- 0.158989 \\n0.363636 -- 0.138764 \\n0.181818 -- 0.141787 \\n0.454545 -- 0.171458 \\n0.181818 -- 0.182186 \\n0.0909091 -- 0.136377 \\n0.272727 -- 0.17574 \\n0.181818 -- 0.122878 \\n0 -- 0.16137 \\n0.0909091 -- 0.162285 \\n0.181818 -- 0.148002 \\n0.272727 -- 0.146618 \\n0.0909091 -- 0.188959 \\n0 -- 0.171124 \\n0.0909091 -- 0.154514 \\n0 -- 0.13598 \\n0 -- 0.156983 \\n0 -- 0.159871 \\n0 -- 0.168422 \\n0 -- 0.142402 \\n0.0909091 -- 0.171984 \\n0.272727 -- 0.180888 \\n0 -- 0.167977 \\n0.363636 -- 0.181162 \\n0.0909091 -- 0.163251 \\n0.0909091 -- 0.142042 \\n0.545455 -- 0.177883 \\n0.181818 -- 0.172536 \\n0.0909091 -- 0.185821 \\n0.272727 -- 0.155367 \\n0.0909091 -- 0.165495 \\n0.363636 -- 0.160548 \\n0 -- 0.179453 \\n0 -- 0.164148 \\n0 -- 0.182564 \\n0.0909091 -- 0.150735 \\n0 -- 0.159809 \\n0.181818 -- 0.158527 \\n0 -- 0.159671 \\n0.0909091 -- 0.183154 \\n0.363636 -- 0.150283 \\n0.181818 -- 0.140193 \\n0 -- 0.173939 \\n0 -- 0.167992 \\n0 -- 0.145815 \\n0.272727 -- 0.166894 \\n0.0909091 -- 0.139898 \\n0.0909091 -- 0.141862 \\n0.0909091 -- 0.163333 \\n0.363636 -- 0.182961 \\n0.363636 -- 0.138689 \\n0 -- 0.184858 \\n0.272727 -- 0.161342 \\n0 -- 0.160111 \\n0.454545 -- 0.168585 \\n0.272727 -- 0.178307 \\n0.272727 -- 0.158796 \\n0 -- 0.156788 \\n0 -- 0.180817 \\n0.545455 -- 0.184735 \\n0.454545 -- 0.200249 \\n0.181818 -- 0.184057 \\n0.0909091 -- 0.15414 \\n0 -- 0.197255 \\n0 -- 0.143069 \\n0.454545 -- 0.159492 \\n0.0909091 -- 0.15888 \\n0 -- 0.161352 \\n0.0909091 -- 0.171869 \\n0.636364 -- 0.182203 \\n0.0909091 -- 0.14808 \\n0 -- 0.144351 \\n0 -- 0.147567 \\n0 -- 0.146 \\n0 -- 0.160347 \\n0.0909091 -- 0.169131 \\n0.181818 -- 0.199641 \\n0.181818 -- 0.175112 \\n0 -- 0.166214 \\n0.181818 -- 0.182821 \\n0.181818 -- 0.172377 \\n0.181818 -- 0.137615 \\n0.272727 -- 0.179655 \\n0 -- 0.171993 \\n0 -- 0.2 \\n0 -- 0.157516 \\n0.0909091 -- 0.170071 \\n0.0909091 -- 0.128118 \\n0 -- 0.177694 \\n0 -- 0.169892 \\n0.363636 -- 0.163144 \\n0 -- 0.15863 \\n0 -- 0.17392 \\n0.181818 -- 0.172841 \\n0.272727 -- 0.152154 \\n0.272727 -- 0.162348 \\n0.0909091 -- 0.153532 \\n0 -- 0.170209 \\n0 -- 0.171657 \\n0.545455 -- 0.147142 \\n0.181818 -- 0.174595 \\n0 -- 0.164413 \\n0 -- 0.183827 \\n0 -- 0.199833 \\n0.181818 -- 0.183925 \\n0.272727 -- 0.185529 \\n0.0909091 -- 0.180206 \\n0.363636 -- 0.168867 \\n0.181818 -- 0.181155 \\n0.454545 -- 0.154468 \\n0.272727 -- 0.167753 \\n0.181818 -- 0.198925 \\n0 -- 0.159914 \\n0 -- 0.171311 \\n0.181818 -- 0.145767 \\n0 -- 0.14398 \\n0 -- 0.160521 \\n0.545455 -- 0.391161 \\n0.0909091 -- 0.159444 \\n0 -- 0.160981 \\n0 -- 0.164179 \\n0.181818 -- 0.150027 \\n0 -- 0.175863 \\n0.181818 -- 0.172074 \\n0 -- 0.181387 \\n0 -- 0.185566 \\n0.181818 -- 0.171206 \\n0 -- 0.163773 \\n0.0909091 -- 0.162092 \\n0 -- 0.147798 \\n0.181818 -- 0.142145 \\n0.272727 -- 0.156231 \\n0 -- 0.159649 \\n0.363636 -- 0.168812 \\n0.0909091 -- 0.171954 \\n0.181818 -- 0.171218 \\n0 -- 0.172569 \\n0 -- 0.137021 \\n0.545455 -- 0.170342 \\n0.636364 -- 0.164714 \\n0.454545 -- 0.155065 \\n0.181818 -- 0.182002 \\n0 -- 0.149044 \\n0 -- 0.171103 \\n0.0909091 -- 0.19143 \\n0 -- 0.170247 \\n0.272727 -- 0.136206 \\n0 -- 0.172568 \\n0.181818 -- 0.150922 \\n0.272727 -- 0.160252 \\n0.272727 -- 0.161182 \\n0.181818 -- 0.161967 \\n0.0909091 -- 0.16288 \\n0.363636 -- 0.160696 \\n0.181818 -- 0.157529 \\n0 -- 0.161756 \\n0.363636 -- 0.152208 \\n0.0909091 -- 0.145055 \\n0.0909091 -- 0.194727 \\n0.272727 -- 0.18095 \\n0.0909091 -- 0.161112 \\n0 -- 0.161282 \\n0.181818 -- 0.169656 \\n0.272727 -- 0.171413 \\n0.272727 -- 0.181055 \\n0.272727 -- 0.167599 \\n0.818182 -- 0.137754 \\n0.454545 -- 0.157499 \\n0 -- 0.144955 \\n0.0909091 -- 0.171701 \\n0.636364 -- 0.188287 \\n0.181818 -- 0.172819 \\n0.363636 -- 0.182434 \\n0.0909091 -- 0.157849 \\n0 -- 0.171458 \\n0.363636 -- 0.162054 \\n0.454545 -- 0.173505 \\n0 -- 0.171843 \\n0.363636 -- 0.171699 \\n0 -- 0.160972 \\n0.181818 -- 0.168354 \\n0 -- 0.158063 \\n0.0909091 -- 0.15999 \\n0 -- 0.160337 \\n0.0909091 -- 0.139685 \\n0.181818 -- 0.159891 \\n0.545455 -- 0.171796 \\n0 -- 0.159485 \\n0.363636 -- 0.163531 \\n0.181818 -- 0.141867 \\n0 -- 0.197794 \\n0.272727 -- 0.163353 \\n0.0909091 -- 0.197778 \\n0 -- 0.163749 \\n0.181818 -- 0.167786 \\n0.272727 -- 0.176493 \\n0 -- 0.180912 \\n0 -- 0.15901 \\n0.0909091 -- 0.182752 \\n0.363636 -- 0.168707 \\n0 -- 0.183359 \\n0.0909091 -- 0.160725 \\n0.454545 -- 0.198671 \\n0 -- 0.146482 \\n0.272727 -- 0.17001 \\n0.545455 -- 0.173515 \\n0.181818 -- 0.142934 \\n0.636364 -- 0.171426 \\n0 -- 0.1619 \\n0 -- 0.170332 \\n0.272727 -- 0.162293 \\n0 -- 0.200982 \\n0.181818 -- 0.158125 \\n0.181818 -- 0.15798 \\n0.181818 -- 0.1601 \\n0.454545 -- 0.157663 \\n0 -- 0.148099 \\n0.363636 -- 0.158773 \\n0.0909091 -- 0.157512 \\n0.363636 -- 0.145908 \\n0 -- 0.170277 \\n0.0909091 -- 0.174829 \\n0.0909091 -- 0.149711 \\n0.0909091 -- 0.192081 \\n0 -- 0.167796 \\n0.272727 -- 0.158764 \\n0.363636 -- 0.165889 \\n0.0909091 -- 0.158948 \\n0 -- 0.167287 \\n0 -- 0.170755 \\n0 -- 0.14484 \\n0.181818 -- 0.157885 \\n0 -- 0.144265 \\n0.0909091 -- 0.145789 \\n0.0909091 -- 0.171315 \\n0.0909091 -- 0.167784 \\n0 -- 0.145597 \\n0.454545 -- 0.166297 \\n0.181818 -- 0.163765 \\n0.181818 -- 0.198844 \\n0.0909091 -- 0.157128 \\n0.272727 -- 0.180953 \\n0.0909091 -- 0.157663 \\n0 -- 0.162816 \\n0.181818 -- 0.162088 \\n0 -- 0.142815 \\n0 -- 0.157904 \\n0.181818 -- 0.180728 \\n0 -- 0.157864 \\n0.181818 -- 0.153967 \\n0.272727 -- 0.172219 \\n0.181818 -- 0.159918 \\n0 -- 0.138869 \\n0.181818 -- 0.162768 \\n0.272727 -- 0.195505 \\n0.0909091 -- 0.18185 \\n0.0909091 -- 0.157549 \\n0.272727 -- 0.154269 \\n0.0909091 -- 0.17374 \\n0 -- 0.200641 \\n0.272727 -- 0.172626 \\n0.181818 -- 0.182031 \\n0 -- 0.172437 \\n0.0909091 -- 0.167238 \\n0.0909091 -- 0.178206 \\n0 -- 0.162987 \\n0 -- 0.195322 \\n0 -- 0.156578 \\n0.363636 -- 0.172718 \\n0 -- 0.168401 \\n0.0909091 -- 0.161823 \\n0 -- 0.188864 \\n0 -- 0.137746 \\n0 -- 0.157514 \\n0.0909091 -- 0.181171 \\n0.181818 -- 0.172963 \\n0 -- 0.1995 \\n0.0909091 -- 0.197584 \\n0.272727 -- 0.192088 \\n0.181818 -- 0.172143 \\n0.181818 -- 0.194731 \\n0.272727 -- 0.171073 \\n0.727273 -- 0.161442 \\n0.272727 -- 0.179157 \\n0.181818 -- 0.157636 \\n0.0909091 -- 0.172216 \\n0.0909091 -- 0.182677 \\n0.272727 -- 0.138353 \\n0.0909091 -- 0.162892 \\n0 -- 0.158198 \\n0.454545 -- 0.16969 \\n0 -- 0.201344 \\n0.181818 -- 0.180793 \\n0.181818 -- 0.197459 \\n0.181818 -- 0.158756 \\n0 -- 0.171568 \\n0.181818 -- 0.242471 \\n0 -- 0.165009 \\n0.545455 -- 0.158676 \\n0 -- 0.159102 \\n0.181818 -- 0.181944 \\n0.272727 -- 0.150056 \\n0.181818 -- 0.154897 \\n0.636364 -- 0.199283 \\n0.272727 -- 0.186851 \\n0.181818 -- 0.138807 \\n0 -- 0.201261 \\n0.272727 -- 0.150094 \\n0.454545 -- 0.200522 \\n0.363636 -- 0.155942 \\n0 -- 0.180744 \\n0.181818 -- 0.16262 \\n0.181818 -- 0.168057 \\n0 -- 0.131868 \\n0.0909091 -- 0.181472 \\n0.0909091 -- 0.161398 \\n0.0909091 -- 0.149482 \\n0.0909091 -- 0.180185 \\n0.0909091 -- 0.177968 \\n0.545455 -- 0.178764 \\n0.0909091 -- 0.158192 \\n0.181818 -- 0.170191 \\n0.181818 -- 0.163548 \\n0.454545 -- 0.192677 \\n0.0909091 -- 0.136622 \\n0.0909091 -- 0.142586 \\n0 -- 0.1797 \\n0.181818 -- 0.140535 \\n0.272727 -- 0.142015 \\n0.0909091 -- 0.129849 \\n0.636364 -- 0.165505 \\n0 -- 0.171866 \\n0.181818 -- 0.164624 \\n0.545455 -- 0.194864 \\n0.454545 -- 0.171681 \\n0.454545 -- 0.159471 \\n0.181818 -- 0.141319 \\n0.0909091 -- 0.172639 \\n0.0909091 -- 0.160598 \\n0.0909091 -- 0.199371 \\n0 -- 0.192908 \\n0 -- 0.180742 \\n0.181818 -- 0.162333 \\n0.454545 -- 0.164514 \\n0 -- 0.156238 \\n0.181818 -- 0.181683 \\n0 -- 0.161735 \\n0.0909091 -- 0.158424 \\n0.272727 -- 0.163108 \\n0 -- 0.163567 \\n0 -- 0.161175 \\n0.181818 -- 0.172324 \\n0.272727 -- 0.158964 \\n0 -- 0.149426 \\n0.363636 -- 0.16441 \\n0.272727 -- 0.157031 \\n0 -- 0.157236 \\n0.272727 -- 0.159613 \\n0 -- 0.144399 \\n0.181818 -- 0.170741 \\n0 -- 0.170537 \\n0.363636 -- 0.170607 \\n0.0909091 -- 0.155516 \\n0.0909091 -- 0.376096 \\n0.454545 -- 0.181376 \\n0.181818 -- 0.181775 \\n0.0909091 -- 0.188804 \\n0 -- 0.112827 \\n0.272727 -- 0.160781 \\n0.0909091 -- 0.146482 \\n0 -- 0.171544 \\n0 -- 0.147788 \\n0 -- 0.149514 \\n0.363636 -- 0.172802 \\n0 -- 0.151678 \\n0 -- 0.139571 \\n0.181818 -- 0.140532 \\n0.0909091 -- 0.164503 \\n0.181818 -- 0.17704 \\n0 -- 0.157815 \\n0.0909091 -- 0.156309 \\n0.454545 -- 0.171625 \\n0.0909091 -- 0.171251 \\n0 -- 0.162429 \\n0.0909091 -- 0.138379 \\n0 -- 0.157219 \\n0.272727 -- 0.182794 \\n0 -- 0.163268 \\n0.181818 -- 0.15743 \\n0.0909091 -- 0.161365 \\n0.272727 -- 0.163067 \\n0.0909091 -- 0.154264 \\n0.363636 -- 0.159896 \\n0 -- 0.138473 \\n0.454545 -- 0.202711 \\n0.181818 -- 0.1636 \\n0.272727 -- 0.161412 \\n0.363636 -- 0.159221 \\n0.0909091 -- 0.192728 \\n0.0909091 -- 0.171996 \\n0.0909091 -- 0.162126 \\n0.454545 -- 0.166172 \\n0 -- 0.196883 \\n0.545455 -- 0.37686 \\n0.0909091 -- 0.218908 \\n0.0909091 -- 0.153321 \\n0 -- 0.142499 \\n0 -- 0.157679 \\n0.0909091 -- 0.151656 \\n0.181818 -- 0.178543 \\n0.181818 -- 0.1706 \\n0 -- 0.181551 \\n0 -- 0.15802 \\n0.0909091 -- 0.169474 \\n0 -- 0.15907 \\n0.545455 -- 0.158608 \\n0.0909091 -- 0.175585 \\n0.545455 -- 0.181177 \\n0.181818 -- 0.13899 \\n0.181818 -- 0.160041 \\n0.0909091 -- 0.191862 \\n0.181818 -- 0.150164 \\n0.181818 -- 0.156885 \\n0.0909091 -- 0.181296 \\n0 -- 0.156852 \\n0.181818 -- 0.158618 \\n0.272727 -- 0.087663 \\n0 -- 0.170475 \\n0 -- 0.174308 \\n0 -- 0.171517 \\n0.181818 -- 0.180397 \\n0.181818 -- 0.190924 \\n0.272727 -- 0.182849 \\n0.454545 -- 0.165854 \\n0.0909091 -- 0.165164 \\n0.636364 -- 0.16856 \\n0 -- 0.144317 \\n0.545455 -- 0.180242 \\n0.181818 -- 0.199605 \\n0.272727 -- 0.171928 \\n0.363636 -- 0.165245 \\n0 -- 0.168021 \\n0.272727 -- 0.163089 \\n0.0909091 -- 0.157346 \\n0.0909091 -- 0.165909 \\n0 -- 0.170401 \\n0 -- 0.13734 \\n0.0909091 -- 0.181613 \\n0.0909091 -- 0.15034 \\n0.181818 -- 0.15833 \\n0.272727 -- 0.1498 \\n0.181818 -- 0.160335 \\n0.181818 -- 0.0961005 \\n0 -- 0.171988 \\n0 -- 0.172514 \\n0.0909091 -- 0.390414 \\n0 -- 0.166792 \\n0 -- 0.161822 \\n0.545455 -- 0.171934 \\n0.272727 -- 0.175795 \\n0.0909091 -- 0.201002 \\n0.0909091 -- 0.159536 \\n0 -- 0.159695 \\n0.363636 -- 0.165878 \\n0 -- 0.155757 \\n0.0909091 -- 0.17034 \\n0 -- 0.175691 \\n0 -- 0.14371 \\n0.181818 -- 0.172152 \\n0.181818 -- 0.20101 \\n0.363636 -- 0.173468 \\n0.181818 -- 0.18156 \\n0.181818 -- 0.154857 \\n0.363636 -- 0.15772 \\n0.272727 -- 0.164887 \\n0.0909091 -- 0.19608 \\n0 -- 0.145914 \\n0 -- 0.172945 \\n0.181818 -- 0.14767 \\n0.0909091 -- 0.17242 \\n0 -- 0.166532 \\n0 -- 0.147435 \\n0 -- 0.149327 \\n0.0909091 -- 0.168155 \\n0 -- 0.179369 \\n0 -- 0.151155 \"\"\"'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puntos_rojos = \"\"\"\n",
    "0.452128 -- 0.512952 \n",
    "0.335106 -- 0.450972 \n",
    "0.720745 -- 0.699826 \n",
    "0.452128 -- 0.316391 \n",
    "0.478723 -- 0.485926 \n",
    "0.505319 -- 0.466812 \n",
    "0.106383 -- 0.102773 \n",
    "0.452128 -- 0.528374 \n",
    "0.265957 -- 0.303581 \n",
    "0.531915 -- 0.593725 \n",
    "0.159574 -- 0.170368 \n",
    "0.265957 -- 0.284208 \n",
    "0.210106 -- 0.24886 \n",
    "0.531915 -- 0.452761 \n",
    "0.191489 -- 0.322875 \n",
    "0.505319 -- 0.617044 \n",
    "0.292553 -- 0.312299 \n",
    "0.62234 -- 0.664819 \n",
    "0.489362 -- 0.541948 \n",
    "0.691489 -- 0.67808 \n",
    "0.345745 -- 0.279338 \n",
    "0.930851 -- 0.886249 \n",
    "0.667553 -- 0.749834 \n",
    "0.239362 -- 0.186453 \n",
    "0.452128 -- 0.557903 \n",
    "0.452128 -- 0.467397 \n",
    "0.319149 -- 0.322784 \n",
    "0.18617 -- 0.245781 \n",
    "0.452128 -- 0.529937 \n",
    "0.345745 -- 0.422118 \n",
    "0.159574 -- 0.117348 \n",
    "0.276596 -- 0.300236 \n",
    "0.271277 -- 0.261483 \n",
    "0.601064 -- 0.53731 \n",
    "0.106383 -- 0.106906 \n",
    "0.771277 -- 0.737039 \n",
    "0.132979 -- 0.117806 \n",
    "0.425532 -- 0.38806 \n",
    "0.106383 -- 0.0852231 \n",
    "0.0265957 -- 0.0715542 \n",
    "0.106383 -- 0.125054 \n",
    "0.398936 -- 0.520703 \n",
    "0.718085 -- 0.730097 \n",
    "0.452128 -- 0.477116 \n",
    "0.132979 -- 0.12978 \n",
    "0.106383 -- 0.113908 \n",
    "0.265957 -- 0.242401 \n",
    "0.75266 -- 0.660654 \n",
    "0.319149 -- 0.334541 \n",
    "0.531915 -- 0.545679 \n",
    "0.132979 -- 0.0999721 \n",
    "0.398936 -- 0.41336 \n",
    "0.505319 -- 0.362588 \n",
    "0.718085 -- 0.714198 \n",
    "0.345745 -- 0.452582 \n",
    "0.18617 -- 0.141792 \n",
    "0.292553 -- 0.226145 \n",
    "0.292553 -- 0.284012 \n",
    "0.425532 -- 0.435784 \n",
    "0.425532 -- 0.42004 \n",
    "0.0797872 -- 0.112105 \n",
    "0.359043 -- 0.277702 \n",
    "0.473404 -- 0.435648 \n",
    "0.37234 -- 0.315978 \n",
    "0.321809 -- 0.474549 \n",
    "0.425532 -- 0.484154 \n",
    "0.428191 -- 0.475164 \n",
    "0.531915 -- 0.528077 \n",
    "0.289894 -- 0.246952 \n",
    "0.159574 -- 0.132199 \n",
    "0.345745 -- 0.307945 \n",
    "0.106383 -- 0.093957 \n",
    "0.345745 -- 0.446079 \n",
    "0.239362 -- 0.393941 \n",
    "0.228723 -- 0.323616 \n",
    "0.505319 -- 0.420778 \n",
    "0.159574 -- 0.108247 \n",
    "0.18617 -- 0.186084 \n",
    "0.478723 -- 0.461432 \"\"\"\n",
    "\n",
    "'''puntos_rosas = \"\"\"0.0909091 -- 0.184661 \n",
    "0.0909091 -- 0.176442 \n",
    "0.272727 -- 0.153274 \n",
    "0.0909091 -- 0.154304 \n",
    "0.272727 -- 0.184137 \n",
    "0 -- 0.164192 \n",
    "0.363636 -- 0.169845 \n",
    "0 -- 0.15867 \n",
    "0.272727 -- 0.172583 \n",
    "0.0909091 -- 0.173976 \n",
    "0.181818 -- 0.164771 \n",
    "0 -- 0.0928139 \n",
    "0.636364 -- 0.187773 \n",
    "0 -- 0.150008 \n",
    "0.272727 -- 0.171904 \n",
    "0 -- 0.166369 \n",
    "0.363636 -- 0.171416 \n",
    "0.0909091 -- 0.154811 \n",
    "0.0909091 -- 0.169766 \n",
    "0.272727 -- 0.182663 \n",
    "0 -- 0.161647 \n",
    "0 -- 0.160613 \n",
    "0.636364 -- 0.154855 \n",
    "0.363636 -- 0.161513 \n",
    "0.454545 -- 0.144694 \n",
    "0.272727 -- 0.14977 \n",
    "0.0909091 -- 0.160532 \n",
    "0.0909091 -- 0.201691 \n",
    "0.272727 -- 0.156351 \n",
    "0.0909091 -- 0.13097 \n",
    "0 -- 0.180985 \n",
    "0.181818 -- 0.169247 \n",
    "0.363636 -- 0.173747 \n",
    "0.181818 -- 0.157044 \n",
    "0.181818 -- 0.0986682 \n",
    "0 -- 0.132816 \n",
    "0 -- 0.171388 \n",
    "0 -- 0.163375 \n",
    "0.272727 -- 0.164469 \n",
    "0 -- 0.166233 \n",
    "0.0909091 -- 0.157515 \n",
    "0.0909091 -- 0.149029 \n",
    "0.272727 -- 0.158062 \n",
    "0.363636 -- 0.161787 \n",
    "0.272727 -- 0.169089 \n",
    "0.0909091 -- 0.153206 \n",
    "0.0909091 -- 0.164165 \n",
    "0.0909091 -- 0.160652 \n",
    "0.0909091 -- 0.159343 \n",
    "0.0909091 -- 0.171151 \n",
    "0.0909091 -- 0.140034 \n",
    "0.818182 -- 0.376479 \n",
    "0.545455 -- 0.169724 \n",
    "0 -- 0.165767 \n",
    "0.272727 -- 0.189385 \n",
    "0.272727 -- 0.162908 \n",
    "0 -- 0.150688 \n",
    "0.0909091 -- 0.187137 \n",
    "0.363636 -- 0.164585 \n",
    "0.0909091 -- 0.160835 \n",
    "0.272727 -- 0.158989 \n",
    "0.363636 -- 0.138764 \n",
    "0.181818 -- 0.141787 \n",
    "0.454545 -- 0.171458 \n",
    "0.181818 -- 0.182186 \n",
    "0.0909091 -- 0.136377 \n",
    "0.272727 -- 0.17574 \n",
    "0.181818 -- 0.122878 \n",
    "0 -- 0.16137 \n",
    "0.0909091 -- 0.162285 \n",
    "0.181818 -- 0.148002 \n",
    "0.272727 -- 0.146618 \n",
    "0.0909091 -- 0.188959 \n",
    "0 -- 0.171124 \n",
    "0.0909091 -- 0.154514 \n",
    "0 -- 0.13598 \n",
    "0 -- 0.156983 \n",
    "0 -- 0.159871 \n",
    "0 -- 0.168422 \n",
    "0 -- 0.142402 \n",
    "0.0909091 -- 0.171984 \n",
    "0.272727 -- 0.180888 \n",
    "0 -- 0.167977 \n",
    "0.363636 -- 0.181162 \n",
    "0.0909091 -- 0.163251 \n",
    "0.0909091 -- 0.142042 \n",
    "0.545455 -- 0.177883 \n",
    "0.181818 -- 0.172536 \n",
    "0.0909091 -- 0.185821 \n",
    "0.272727 -- 0.155367 \n",
    "0.0909091 -- 0.165495 \n",
    "0.363636 -- 0.160548 \n",
    "0 -- 0.179453 \n",
    "0 -- 0.164148 \n",
    "0 -- 0.182564 \n",
    "0.0909091 -- 0.150735 \n",
    "0 -- 0.159809 \n",
    "0.181818 -- 0.158527 \n",
    "0 -- 0.159671 \n",
    "0.0909091 -- 0.183154 \n",
    "0.363636 -- 0.150283 \n",
    "0.181818 -- 0.140193 \n",
    "0 -- 0.173939 \n",
    "0 -- 0.167992 \n",
    "0 -- 0.145815 \n",
    "0.272727 -- 0.166894 \n",
    "0.0909091 -- 0.139898 \n",
    "0.0909091 -- 0.141862 \n",
    "0.0909091 -- 0.163333 \n",
    "0.363636 -- 0.182961 \n",
    "0.363636 -- 0.138689 \n",
    "0 -- 0.184858 \n",
    "0.272727 -- 0.161342 \n",
    "0 -- 0.160111 \n",
    "0.454545 -- 0.168585 \n",
    "0.272727 -- 0.178307 \n",
    "0.272727 -- 0.158796 \n",
    "0 -- 0.156788 \n",
    "0 -- 0.180817 \n",
    "0.545455 -- 0.184735 \n",
    "0.454545 -- 0.200249 \n",
    "0.181818 -- 0.184057 \n",
    "0.0909091 -- 0.15414 \n",
    "0 -- 0.197255 \n",
    "0 -- 0.143069 \n",
    "0.454545 -- 0.159492 \n",
    "0.0909091 -- 0.15888 \n",
    "0 -- 0.161352 \n",
    "0.0909091 -- 0.171869 \n",
    "0.636364 -- 0.182203 \n",
    "0.0909091 -- 0.14808 \n",
    "0 -- 0.144351 \n",
    "0 -- 0.147567 \n",
    "0 -- 0.146 \n",
    "0 -- 0.160347 \n",
    "0.0909091 -- 0.169131 \n",
    "0.181818 -- 0.199641 \n",
    "0.181818 -- 0.175112 \n",
    "0 -- 0.166214 \n",
    "0.181818 -- 0.182821 \n",
    "0.181818 -- 0.172377 \n",
    "0.181818 -- 0.137615 \n",
    "0.272727 -- 0.179655 \n",
    "0 -- 0.171993 \n",
    "0 -- 0.2 \n",
    "0 -- 0.157516 \n",
    "0.0909091 -- 0.170071 \n",
    "0.0909091 -- 0.128118 \n",
    "0 -- 0.177694 \n",
    "0 -- 0.169892 \n",
    "0.363636 -- 0.163144 \n",
    "0 -- 0.15863 \n",
    "0 -- 0.17392 \n",
    "0.181818 -- 0.172841 \n",
    "0.272727 -- 0.152154 \n",
    "0.272727 -- 0.162348 \n",
    "0.0909091 -- 0.153532 \n",
    "0 -- 0.170209 \n",
    "0 -- 0.171657 \n",
    "0.545455 -- 0.147142 \n",
    "0.181818 -- 0.174595 \n",
    "0 -- 0.164413 \n",
    "0 -- 0.183827 \n",
    "0 -- 0.199833 \n",
    "0.181818 -- 0.183925 \n",
    "0.272727 -- 0.185529 \n",
    "0.0909091 -- 0.180206 \n",
    "0.363636 -- 0.168867 \n",
    "0.181818 -- 0.181155 \n",
    "0.454545 -- 0.154468 \n",
    "0.272727 -- 0.167753 \n",
    "0.181818 -- 0.198925 \n",
    "0 -- 0.159914 \n",
    "0 -- 0.171311 \n",
    "0.181818 -- 0.145767 \n",
    "0 -- 0.14398 \n",
    "0 -- 0.160521 \n",
    "0.545455 -- 0.391161 \n",
    "0.0909091 -- 0.159444 \n",
    "0 -- 0.160981 \n",
    "0 -- 0.164179 \n",
    "0.181818 -- 0.150027 \n",
    "0 -- 0.175863 \n",
    "0.181818 -- 0.172074 \n",
    "0 -- 0.181387 \n",
    "0 -- 0.185566 \n",
    "0.181818 -- 0.171206 \n",
    "0 -- 0.163773 \n",
    "0.0909091 -- 0.162092 \n",
    "0 -- 0.147798 \n",
    "0.181818 -- 0.142145 \n",
    "0.272727 -- 0.156231 \n",
    "0 -- 0.159649 \n",
    "0.363636 -- 0.168812 \n",
    "0.0909091 -- 0.171954 \n",
    "0.181818 -- 0.171218 \n",
    "0 -- 0.172569 \n",
    "0 -- 0.137021 \n",
    "0.545455 -- 0.170342 \n",
    "0.636364 -- 0.164714 \n",
    "0.454545 -- 0.155065 \n",
    "0.181818 -- 0.182002 \n",
    "0 -- 0.149044 \n",
    "0 -- 0.171103 \n",
    "0.0909091 -- 0.19143 \n",
    "0 -- 0.170247 \n",
    "0.272727 -- 0.136206 \n",
    "0 -- 0.172568 \n",
    "0.181818 -- 0.150922 \n",
    "0.272727 -- 0.160252 \n",
    "0.272727 -- 0.161182 \n",
    "0.181818 -- 0.161967 \n",
    "0.0909091 -- 0.16288 \n",
    "0.363636 -- 0.160696 \n",
    "0.181818 -- 0.157529 \n",
    "0 -- 0.161756 \n",
    "0.363636 -- 0.152208 \n",
    "0.0909091 -- 0.145055 \n",
    "0.0909091 -- 0.194727 \n",
    "0.272727 -- 0.18095 \n",
    "0.0909091 -- 0.161112 \n",
    "0 -- 0.161282 \n",
    "0.181818 -- 0.169656 \n",
    "0.272727 -- 0.171413 \n",
    "0.272727 -- 0.181055 \n",
    "0.272727 -- 0.167599 \n",
    "0.818182 -- 0.137754 \n",
    "0.454545 -- 0.157499 \n",
    "0 -- 0.144955 \n",
    "0.0909091 -- 0.171701 \n",
    "0.636364 -- 0.188287 \n",
    "0.181818 -- 0.172819 \n",
    "0.363636 -- 0.182434 \n",
    "0.0909091 -- 0.157849 \n",
    "0 -- 0.171458 \n",
    "0.363636 -- 0.162054 \n",
    "0.454545 -- 0.173505 \n",
    "0 -- 0.171843 \n",
    "0.363636 -- 0.171699 \n",
    "0 -- 0.160972 \n",
    "0.181818 -- 0.168354 \n",
    "0 -- 0.158063 \n",
    "0.0909091 -- 0.15999 \n",
    "0 -- 0.160337 \n",
    "0.0909091 -- 0.139685 \n",
    "0.181818 -- 0.159891 \n",
    "0.545455 -- 0.171796 \n",
    "0 -- 0.159485 \n",
    "0.363636 -- 0.163531 \n",
    "0.181818 -- 0.141867 \n",
    "0 -- 0.197794 \n",
    "0.272727 -- 0.163353 \n",
    "0.0909091 -- 0.197778 \n",
    "0 -- 0.163749 \n",
    "0.181818 -- 0.167786 \n",
    "0.272727 -- 0.176493 \n",
    "0 -- 0.180912 \n",
    "0 -- 0.15901 \n",
    "0.0909091 -- 0.182752 \n",
    "0.363636 -- 0.168707 \n",
    "0 -- 0.183359 \n",
    "0.0909091 -- 0.160725 \n",
    "0.454545 -- 0.198671 \n",
    "0 -- 0.146482 \n",
    "0.272727 -- 0.17001 \n",
    "0.545455 -- 0.173515 \n",
    "0.181818 -- 0.142934 \n",
    "0.636364 -- 0.171426 \n",
    "0 -- 0.1619 \n",
    "0 -- 0.170332 \n",
    "0.272727 -- 0.162293 \n",
    "0 -- 0.200982 \n",
    "0.181818 -- 0.158125 \n",
    "0.181818 -- 0.15798 \n",
    "0.181818 -- 0.1601 \n",
    "0.454545 -- 0.157663 \n",
    "0 -- 0.148099 \n",
    "0.363636 -- 0.158773 \n",
    "0.0909091 -- 0.157512 \n",
    "0.363636 -- 0.145908 \n",
    "0 -- 0.170277 \n",
    "0.0909091 -- 0.174829 \n",
    "0.0909091 -- 0.149711 \n",
    "0.0909091 -- 0.192081 \n",
    "0 -- 0.167796 \n",
    "0.272727 -- 0.158764 \n",
    "0.363636 -- 0.165889 \n",
    "0.0909091 -- 0.158948 \n",
    "0 -- 0.167287 \n",
    "0 -- 0.170755 \n",
    "0 -- 0.14484 \n",
    "0.181818 -- 0.157885 \n",
    "0 -- 0.144265 \n",
    "0.0909091 -- 0.145789 \n",
    "0.0909091 -- 0.171315 \n",
    "0.0909091 -- 0.167784 \n",
    "0 -- 0.145597 \n",
    "0.454545 -- 0.166297 \n",
    "0.181818 -- 0.163765 \n",
    "0.181818 -- 0.198844 \n",
    "0.0909091 -- 0.157128 \n",
    "0.272727 -- 0.180953 \n",
    "0.0909091 -- 0.157663 \n",
    "0 -- 0.162816 \n",
    "0.181818 -- 0.162088 \n",
    "0 -- 0.142815 \n",
    "0 -- 0.157904 \n",
    "0.181818 -- 0.180728 \n",
    "0 -- 0.157864 \n",
    "0.181818 -- 0.153967 \n",
    "0.272727 -- 0.172219 \n",
    "0.181818 -- 0.159918 \n",
    "0 -- 0.138869 \n",
    "0.181818 -- 0.162768 \n",
    "0.272727 -- 0.195505 \n",
    "0.0909091 -- 0.18185 \n",
    "0.0909091 -- 0.157549 \n",
    "0.272727 -- 0.154269 \n",
    "0.0909091 -- 0.17374 \n",
    "0 -- 0.200641 \n",
    "0.272727 -- 0.172626 \n",
    "0.181818 -- 0.182031 \n",
    "0 -- 0.172437 \n",
    "0.0909091 -- 0.167238 \n",
    "0.0909091 -- 0.178206 \n",
    "0 -- 0.162987 \n",
    "0 -- 0.195322 \n",
    "0 -- 0.156578 \n",
    "0.363636 -- 0.172718 \n",
    "0 -- 0.168401 \n",
    "0.0909091 -- 0.161823 \n",
    "0 -- 0.188864 \n",
    "0 -- 0.137746 \n",
    "0 -- 0.157514 \n",
    "0.0909091 -- 0.181171 \n",
    "0.181818 -- 0.172963 \n",
    "0 -- 0.1995 \n",
    "0.0909091 -- 0.197584 \n",
    "0.272727 -- 0.192088 \n",
    "0.181818 -- 0.172143 \n",
    "0.181818 -- 0.194731 \n",
    "0.272727 -- 0.171073 \n",
    "0.727273 -- 0.161442 \n",
    "0.272727 -- 0.179157 \n",
    "0.181818 -- 0.157636 \n",
    "0.0909091 -- 0.172216 \n",
    "0.0909091 -- 0.182677 \n",
    "0.272727 -- 0.138353 \n",
    "0.0909091 -- 0.162892 \n",
    "0 -- 0.158198 \n",
    "0.454545 -- 0.16969 \n",
    "0 -- 0.201344 \n",
    "0.181818 -- 0.180793 \n",
    "0.181818 -- 0.197459 \n",
    "0.181818 -- 0.158756 \n",
    "0 -- 0.171568 \n",
    "0.181818 -- 0.242471 \n",
    "0 -- 0.165009 \n",
    "0.545455 -- 0.158676 \n",
    "0 -- 0.159102 \n",
    "0.181818 -- 0.181944 \n",
    "0.272727 -- 0.150056 \n",
    "0.181818 -- 0.154897 \n",
    "0.636364 -- 0.199283 \n",
    "0.272727 -- 0.186851 \n",
    "0.181818 -- 0.138807 \n",
    "0 -- 0.201261 \n",
    "0.272727 -- 0.150094 \n",
    "0.454545 -- 0.200522 \n",
    "0.363636 -- 0.155942 \n",
    "0 -- 0.180744 \n",
    "0.181818 -- 0.16262 \n",
    "0.181818 -- 0.168057 \n",
    "0 -- 0.131868 \n",
    "0.0909091 -- 0.181472 \n",
    "0.0909091 -- 0.161398 \n",
    "0.0909091 -- 0.149482 \n",
    "0.0909091 -- 0.180185 \n",
    "0.0909091 -- 0.177968 \n",
    "0.545455 -- 0.178764 \n",
    "0.0909091 -- 0.158192 \n",
    "0.181818 -- 0.170191 \n",
    "0.181818 -- 0.163548 \n",
    "0.454545 -- 0.192677 \n",
    "0.0909091 -- 0.136622 \n",
    "0.0909091 -- 0.142586 \n",
    "0 -- 0.1797 \n",
    "0.181818 -- 0.140535 \n",
    "0.272727 -- 0.142015 \n",
    "0.0909091 -- 0.129849 \n",
    "0.636364 -- 0.165505 \n",
    "0 -- 0.171866 \n",
    "0.181818 -- 0.164624 \n",
    "0.545455 -- 0.194864 \n",
    "0.454545 -- 0.171681 \n",
    "0.454545 -- 0.159471 \n",
    "0.181818 -- 0.141319 \n",
    "0.0909091 -- 0.172639 \n",
    "0.0909091 -- 0.160598 \n",
    "0.0909091 -- 0.199371 \n",
    "0 -- 0.192908 \n",
    "0 -- 0.180742 \n",
    "0.181818 -- 0.162333 \n",
    "0.454545 -- 0.164514 \n",
    "0 -- 0.156238 \n",
    "0.181818 -- 0.181683 \n",
    "0 -- 0.161735 \n",
    "0.0909091 -- 0.158424 \n",
    "0.272727 -- 0.163108 \n",
    "0 -- 0.163567 \n",
    "0 -- 0.161175 \n",
    "0.181818 -- 0.172324 \n",
    "0.272727 -- 0.158964 \n",
    "0 -- 0.149426 \n",
    "0.363636 -- 0.16441 \n",
    "0.272727 -- 0.157031 \n",
    "0 -- 0.157236 \n",
    "0.272727 -- 0.159613 \n",
    "0 -- 0.144399 \n",
    "0.181818 -- 0.170741 \n",
    "0 -- 0.170537 \n",
    "0.363636 -- 0.170607 \n",
    "0.0909091 -- 0.155516 \n",
    "0.0909091 -- 0.376096 \n",
    "0.454545 -- 0.181376 \n",
    "0.181818 -- 0.181775 \n",
    "0.0909091 -- 0.188804 \n",
    "0 -- 0.112827 \n",
    "0.272727 -- 0.160781 \n",
    "0.0909091 -- 0.146482 \n",
    "0 -- 0.171544 \n",
    "0 -- 0.147788 \n",
    "0 -- 0.149514 \n",
    "0.363636 -- 0.172802 \n",
    "0 -- 0.151678 \n",
    "0 -- 0.139571 \n",
    "0.181818 -- 0.140532 \n",
    "0.0909091 -- 0.164503 \n",
    "0.181818 -- 0.17704 \n",
    "0 -- 0.157815 \n",
    "0.0909091 -- 0.156309 \n",
    "0.454545 -- 0.171625 \n",
    "0.0909091 -- 0.171251 \n",
    "0 -- 0.162429 \n",
    "0.0909091 -- 0.138379 \n",
    "0 -- 0.157219 \n",
    "0.272727 -- 0.182794 \n",
    "0 -- 0.163268 \n",
    "0.181818 -- 0.15743 \n",
    "0.0909091 -- 0.161365 \n",
    "0.272727 -- 0.163067 \n",
    "0.0909091 -- 0.154264 \n",
    "0.363636 -- 0.159896 \n",
    "0 -- 0.138473 \n",
    "0.454545 -- 0.202711 \n",
    "0.181818 -- 0.1636 \n",
    "0.272727 -- 0.161412 \n",
    "0.363636 -- 0.159221 \n",
    "0.0909091 -- 0.192728 \n",
    "0.0909091 -- 0.171996 \n",
    "0.0909091 -- 0.162126 \n",
    "0.454545 -- 0.166172 \n",
    "0 -- 0.196883 \n",
    "0.545455 -- 0.37686 \n",
    "0.0909091 -- 0.218908 \n",
    "0.0909091 -- 0.153321 \n",
    "0 -- 0.142499 \n",
    "0 -- 0.157679 \n",
    "0.0909091 -- 0.151656 \n",
    "0.181818 -- 0.178543 \n",
    "0.181818 -- 0.1706 \n",
    "0 -- 0.181551 \n",
    "0 -- 0.15802 \n",
    "0.0909091 -- 0.169474 \n",
    "0 -- 0.15907 \n",
    "0.545455 -- 0.158608 \n",
    "0.0909091 -- 0.175585 \n",
    "0.545455 -- 0.181177 \n",
    "0.181818 -- 0.13899 \n",
    "0.181818 -- 0.160041 \n",
    "0.0909091 -- 0.191862 \n",
    "0.181818 -- 0.150164 \n",
    "0.181818 -- 0.156885 \n",
    "0.0909091 -- 0.181296 \n",
    "0 -- 0.156852 \n",
    "0.181818 -- 0.158618 \n",
    "0.272727 -- 0.087663 \n",
    "0 -- 0.170475 \n",
    "0 -- 0.174308 \n",
    "0 -- 0.171517 \n",
    "0.181818 -- 0.180397 \n",
    "0.181818 -- 0.190924 \n",
    "0.272727 -- 0.182849 \n",
    "0.454545 -- 0.165854 \n",
    "0.0909091 -- 0.165164 \n",
    "0.636364 -- 0.16856 \n",
    "0 -- 0.144317 \n",
    "0.545455 -- 0.180242 \n",
    "0.181818 -- 0.199605 \n",
    "0.272727 -- 0.171928 \n",
    "0.363636 -- 0.165245 \n",
    "0 -- 0.168021 \n",
    "0.272727 -- 0.163089 \n",
    "0.0909091 -- 0.157346 \n",
    "0.0909091 -- 0.165909 \n",
    "0 -- 0.170401 \n",
    "0 -- 0.13734 \n",
    "0.0909091 -- 0.181613 \n",
    "0.0909091 -- 0.15034 \n",
    "0.181818 -- 0.15833 \n",
    "0.272727 -- 0.1498 \n",
    "0.181818 -- 0.160335 \n",
    "0.181818 -- 0.0961005 \n",
    "0 -- 0.171988 \n",
    "0 -- 0.172514 \n",
    "0.0909091 -- 0.390414 \n",
    "0 -- 0.166792 \n",
    "0 -- 0.161822 \n",
    "0.545455 -- 0.171934 \n",
    "0.272727 -- 0.175795 \n",
    "0.0909091 -- 0.201002 \n",
    "0.0909091 -- 0.159536 \n",
    "0 -- 0.159695 \n",
    "0.363636 -- 0.165878 \n",
    "0 -- 0.155757 \n",
    "0.0909091 -- 0.17034 \n",
    "0 -- 0.175691 \n",
    "0 -- 0.14371 \n",
    "0.181818 -- 0.172152 \n",
    "0.181818 -- 0.20101 \n",
    "0.363636 -- 0.173468 \n",
    "0.181818 -- 0.18156 \n",
    "0.181818 -- 0.154857 \n",
    "0.363636 -- 0.15772 \n",
    "0.272727 -- 0.164887 \n",
    "0.0909091 -- 0.19608 \n",
    "0 -- 0.145914 \n",
    "0 -- 0.172945 \n",
    "0.181818 -- 0.14767 \n",
    "0.0909091 -- 0.17242 \n",
    "0 -- 0.166532 \n",
    "0 -- 0.147435 \n",
    "0 -- 0.149327 \n",
    "0.0909091 -- 0.168155 \n",
    "0 -- 0.179369 \n",
    "0 -- 0.151155 \"\"\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_cadena_a_tuplas(cadena):\n",
    "    # Separar la cadena en lÃ­neas\n",
    "    lineas = cadena.strip().split(\"\\n\")\n",
    "    # Crear una lista de tuplas a partir de las lÃ­neas\n",
    "    tuplas = []\n",
    "    for linea in lineas:\n",
    "        # Separar los valores por \"--\" y eliminar espacios\n",
    "        valores = linea.split(\"--\")\n",
    "        x = float(valores[0].strip())\n",
    "        y = float(valores[1].strip())\n",
    "        # AÃ±adir la tupla (x, y) a la lista\n",
    "        tuplas.append((x, y))\n",
    "    return tuplas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "puntos_rojos = convertir_cadena_a_tuplas(puntos_rojos)\n",
    "#puntos_rosas = convertir_cadena_a_tuplas(puntos_rosas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "puntos_rojos_ordenados = sorted(puntos_rojos, key=lambda x: x[0])\n",
    "#puntos_rosa_ordenados = sorted(puntos_rosas, key=lambda x: x[0])\n",
    "\n",
    "# Extraer coordenadas para graficar\n",
    "x_rojo = [p[0] for p in puntos_rojos_ordenados]\n",
    "y_rojo = [p[1] for p in puntos_rojos_ordenados]\n",
    "\n",
    "#x_rosa = [p[0] for p in puntos_rosa_ordenados]\n",
    "#y_rosa = [p[1] for p in puntos_rosa_ordenados]\n",
    "\n",
    "# Crear grÃ¡fico\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Graficar los puntos rojos (IteraciÃ³n 2000) y rosa (IteraciÃ³n 1000)\n",
    "plt.scatter(x_rojo, y_rojo, color='red', label='Iteration 2000', alpha=0.7)\n",
    "#plt.scatter(x_rosa, y_rosa, color='blue', label='Iteration 1000', alpha=0.7)\n",
    "\n",
    "# Etiquetas y leyenda en inglÃ©s\n",
    "plt.xlabel('real')\n",
    "plt.ylabel('predected')\n",
    "plt.title('Comparison between value and predicted value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Mostrar grÃ¡fico\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
